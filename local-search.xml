<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>推荐系统实践（项亮）第三章</title>
    <link href="/2022/03/20/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%EF%BC%88%E9%A1%B9%E4%BA%AE%EF%BC%89%E7%AC%AC%E4%B8%89%E7%AB%A0/"/>
    <url>/2022/03/20/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%EF%BC%88%E9%A1%B9%E4%BA%AE%EF%BC%89%E7%AC%AC%E4%B8%89%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>推荐系统实践（项亮）第二章笔记</title>
    <link href="/2022/03/19/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%EF%BC%88%E9%A1%B9%E4%BA%AE%EF%BC%89%E7%AC%AC%E4%BA%8C%E7%AB%A0/"/>
    <url>/2022/03/19/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%EF%BC%88%E9%A1%B9%E4%BA%AE%EF%BC%89%E7%AC%AC%E4%BA%8C%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="第二章-利用用户行为数据"><a href="#第二章-利用用户行为数据" class="headerlink" title="第二章 利用用户行为数据"></a>第二章 利用用户行为数据</h1><p><a href="https://github.com/Magic-Bubble/RecommendSystemPractice/tree/master/Chapter2">本章节代码来源</a></p><p>实现个性化推荐<strong>最理想的情况</strong>是用户注册的时候主动告诉我们他喜欢什么，但其缺点有三：</p><p>1)NLU技术难以理解用户描述兴趣的自然语言.</p><p>2)用户的兴趣不断变化,但用户不会不停地更新兴趣描述.</p><ol start="3"><li>用户不知道自己喜欢什么&#x2F;很难用语言描述自己喜欢什么.因此,需要算法挖掘用户行为数据进而推荐.</li></ol><p>啤酒尿布&#x2F;购物车分析的例子就说明了用户行为数据蕴含不是那么显而易见的规律,个性化推荐算法的任务就是通过计算机发现这些规律.</p><p>基于用户行为分析的推荐算法是个性化推荐系统的重要算法,学术界一般将这种类型的算法称为协同过滤算法.即用户可以不断地与网站互动,使自己的推荐列表能够不断过滤掉自己不感兴趣的物品来满足自己的需求.</p><h2 id="2-1-用户行为数据简介"><a href="#2-1-用户行为数据简介" class="headerlink" title="2.1 用户行为数据简介"></a>2.1 用户行为数据简介</h2><p>推荐系统会汇总原始日志生成描述用户行为的会话日志.这些日志记录了用户的各种行为,如在电子商务网站中这些行为主要包括网页浏览、点击、评分等.</p><p>用户行为在个性化推荐系统中一般分两种（按明确性分）</p><ul><li>显性反馈行为：明确表示对物品喜好的行为，如评分、喜欢&#x2F;不喜欢等</li><li>隐性反馈行为：不能明确反应，如页面浏览（浏览不一定是喜欢，可能只是因为在首页）</li></ul><p>按反馈的方向分为正反馈（用户行为倾向于喜欢该物品）和负反馈（反之）。</p><p>互联网行为有很多种，用统一的方式表示这些所有行为比较困难。一般不同的数据集包含不同的行为.</p><ul><li>无上下文信息的隐性反馈数据集    每条行为记录包含用户ID,物品ID.数据集Book-Crossing</li><li>无上下文信息的显性反馈数据集    每条行为记录包含用户ID,物品ID和用户对物品的评分</li><li>有上下文信息的隐性反馈数据集    每条行为记录包含用户ID,物品ID和用户对物品产生行为的时间戳.数据集Lastfm</li><li>有上下文信息的显性反馈数据集    每条行为记录包含用户ID,物品ID,评分和时间戳.数据集Netflix Prize提供的就是这种类型的数据集.</li></ul><p>本章使用的都是第一种.</p><h2 id="2-2-用户行为分析"><a href="#2-2-用户行为分析" class="headerlink" title="2.2 用户行为分析"></a>2.2 用户行为分析</h2><p>本节介绍用户行为数据中蕴含的一般规律</p><h4 id="2-2-1-用户活跃度和物品流行度的分布"><a href="#2-2-1-用户活跃度和物品流行度的分布" class="headerlink" title="2.2.1 用户活跃度和物品流行度的分布"></a>2.2.1 用户活跃度和物品流行度的分布</h4><p><strong>长尾分布</strong>——流行度大的物品占物品总数少;活跃度大的用户占用户的比例小</p><h4 id="2-2-2-用户活跃度和物品流行度的关系"><a href="#2-2-2-用户活跃度和物品流行度的关系" class="headerlink" title="2.2.2 用户活跃度和物品流行度的关系"></a>2.2.2 用户活跃度和物品流行度的关系</h4><p>一般认为新用户倾向于浏览热门物品,而活跃用户会逐渐开始浏览冷门物品.</p><p>仅基于用户行为设计的推荐算法一般称为系统过滤算法.协同过滤算法有很多种,如<strong>基于邻域的方法</strong>(neighborhood-based),隐语义模型(latent factor model),基于图的随机游走算法(random walk on graph)</p><p>基于邻域的方法主要包含下面两种算法:</p><ul><li>基于用户的协同过滤算法    给用户推荐和他兴趣相似的其他用户喜欢的物品</li><li><strong>基于物品的协同过滤算法</strong>    给用户推荐和他之前喜欢的物品相似的物品</li></ul><h2 id="2-3-实验设计和算法评测"><a href="#2-3-实验设计和算法评测" class="headerlink" title="2.3 实验设计和算法评测"></a>2.3 实验设计和算法评测</h2><h4 id="2-3-1-数据集"><a href="#2-3-1-数据集" class="headerlink" title="2.3.1 数据集"></a>2.3.1 数据集</h4><p>本实验采用GroupLens提供的中等大小版本的MovieLens数据集.</p><p>这是一个评分数据集(1~5分),包含6000多用户对4000多部电影的100万条评分.</p><p>由于本章研究<strong>隐反馈数据集中的TopN推荐</strong>问题,因此忽略数据集的评分记录(TopN推荐的任务是预测用户会不会评分,而非预测在其准备评分的前提下评多少分).</p><h4 id="2-3-2-实验设计"><a href="#2-3-2-实验设计" class="headerlink" title="2.3.2 实验设计"></a>2.3.2 实验设计</h4><p>使用K_Fold分割数据集</p><p>文件结构:</p><figure class="highlight dns"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><pre><code class="hljs dns">├── ml-<span class="hljs-number">1m</span>/<br>    ├── movies.dat     // MovieI<span class="hljs-number">D::</span>Titl<span class="hljs-number">e::</span>Genres<br>    ├── ratings.dat    // UserI<span class="hljs-number">D::</span>MovieI<span class="hljs-number">D::</span>Rating<span class="hljs-number">::</span>Timestamp<br>    ├── users.dat      // UserI<span class="hljs-number">D::</span>Gender<span class="hljs-number">::</span>Ag<span class="hljs-number">e::</span>Occupation<span class="hljs-number">::</span>Zip-code<br></code></pre></td></tr></table></figure><p><strong>对数据集进行划分:</strong></p><p>本实验使用的是<code>ratings.dat</code>文件,首先对其进行预处理:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># 定义装饰器，监控运行时间</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">timmer</span>(<span class="hljs-params">func</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">wrapper</span>(<span class="hljs-params">*args, **kwargs</span>):<br>        start_time = time.time()<br>        res = func(*args, **kwargs)<br>        stop_time = time.time()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Func %s, run time: %s&#x27;</span> % (func.__name__, stop_time - start_time))<br>        <span class="hljs-keyword">return</span> res<br>    <span class="hljs-keyword">return</span> wrapper<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 处理数据:</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Dataset</span>():<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, fp</span>):<br>        <span class="hljs-comment"># fp: data file path</span><br>        self.data = self.loadData(fp)<br>    <br><span class="hljs-meta">    @timmer</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">loadData</span>(<span class="hljs-params">self, fp</span>):<br>        data = []<br>        <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">open</span>(fp):<br>            data.append(<span class="hljs-built_in">tuple</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, l.strip().split(<span class="hljs-string">&#x27;::&#x27;</span>)[:<span class="hljs-number">2</span>])))<br>        <span class="hljs-keyword">return</span> data<br>    <br><span class="hljs-meta">    @timmer</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">splitData</span>(<span class="hljs-params">self, M, k, seed=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        :params: data, 加载的所有(user, item)数据条目</span><br><span class="hljs-string">        :params: M, 划分的数目，最后需要取M折的平均</span><br><span class="hljs-string">        :params: k, 本次是第几次划分，k~[0, M)</span><br><span class="hljs-string">        :params: seed, random的种子数，对于不同的k应设置成一样的</span><br><span class="hljs-string">        :return: train, test</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        train, test = [], []<br>        random.seed(seed)<br>        <span class="hljs-keyword">for</span> user, item <span class="hljs-keyword">in</span> self.data:<br>            <span class="hljs-comment"># 这里与书中的不一致，本人认为取M-1较为合理，因randint是左右都覆盖的</span><br>            <span class="hljs-keyword">if</span> random.randint(<span class="hljs-number">0</span>, M-<span class="hljs-number">1</span>) == k:  <br>                test.append((user, item))<br>            <span class="hljs-keyword">else</span>:<br>                train.append((user, item))<br><br>        <span class="hljs-comment"># 处理成字典的形式，user-&gt;set(items)</span><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_dict</span>(<span class="hljs-params">data</span>):<br>            data_dict = &#123;&#125;<br>            <span class="hljs-keyword">for</span> user, item <span class="hljs-keyword">in</span> data:<br>                <span class="hljs-keyword">if</span> user <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> data_dict:<br>                    data_dict[user] = <span class="hljs-built_in">set</span>()<br>                data_dict[user].add(item)<br>            data_dict = &#123;k: <span class="hljs-built_in">list</span>(data_dict[k]) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> data_dict&#125;<br>            <span class="hljs-keyword">return</span> data_dict<br><br>        <span class="hljs-keyword">return</span> convert_dict(train), convert_dict(test)<br></code></pre></td></tr></table></figure><p>每次实验选取不同的$k(0\leq k\leq M-1)$和<strong>相同的seed</strong>，由于相同的seed产生的随机数序列一样，且范围在$0\sim M-1$，当选取不同的$k$时,得到的test也不同,且test和$k$一一对应,因此能得到$M$个训练&#x2F;测试集.</p><p>这样做是为了防止某次实验过拟合.</p><p>经上述步骤处理后数据格式如下,表示用户ID1看过的电影为ID608,ID3114,ID1246.用户ID2看过的是ID1537和ID2628.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs yaml">&#123;<span class="hljs-attr">1:</span> [<span class="hljs-number">608</span>, <span class="hljs-number">3114</span>, <span class="hljs-number">1246</span>], <span class="hljs-attr">2:</span> [<span class="hljs-number">1537</span>, <span class="hljs-number">2628</span>]&#125;<br></code></pre></td></tr></table></figure><h4 id="2-3-3-评测指标"><a href="#2-3-3-评测指标" class="headerlink" title="2.3.3 评测指标"></a>2.3.3 评测指标</h4><p>对用户$u$推荐$N$个物品(记为$R(U)$),令该用户在测试集上喜欢的物品集合为$T(U)$,可通过$precision$和$recall$评测算法精度:</p><ul><li><p>召回率:label中的评分记录有多少在预测的推荐列表中,因此分母是label中的正样本数.</p></li><li><p>准确率:预测的推荐列表中有多少是发生过的评分记录</p></li></ul><p>e.g.$+$表示label&#x2F;predict中用户喜欢的物品</p><img src="https://hicgoal-img.oss-cn-beijing.aliyuncs.com/img/image-20220316235946240.png" alt="" style="zoom:50%;" /><p>此例有:</p><p>$|U|&#x3D;1(用户总数),N&#x3D;7(推荐列表长度,在这里假设label长度也是7)$,</p><p>$R(U)\cap T(U)&#x3D;4,R(U)&#x3D;7,T(U)&#x3D;5$</p><p>$\Rightarrow recall&#x3D;\frac{\sum_{u\in U}|R(U)\cap T(U)|}{\sum_{u\in U}T(U)}&#x3D;\frac{4}{5},precision&#x3D;\frac{\sum_{u\in U}|R(U)\cap T(U|}{\sum_{u\in U}R(U)}&#x3D;\frac{4}{7}$</p><p>再次强调,该实验的目的是<strong>预测用户会不会评分</strong></p><ul><li><p>覆盖率$Coverage&#x3D;\frac{\cup_{u\in U}\ R(u)}{|I|}$</p></li><li><p>新颖度,在这里使用平均流行度<strong>度量</strong>推荐结果的新颖度,平均流行度越高,新颖度越低.</p></li></ul><p>由于物品流行度分布满足长尾分布,因此在计算平均流行度时对每个物品的流行度取对数,使流行度平均值更加稳定.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Metric</span>():<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, train, test, GetRecommendation</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        :params: train, 训练数据</span><br><span class="hljs-string">        :params: test, 测试数据</span><br><span class="hljs-string">        :params: GetRecommendation, 为某个用户获取推荐物品的接口函数</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        self.train = train<br>        self.test = test<br>        self.GetRecommendation = GetRecommendation<br>        self.recs = self.getRec()<br>        <br>    <span class="hljs-comment"># 为test中的每个用户进行推荐</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">getRec</span>(<span class="hljs-params">self</span>):<br>        recs = &#123;&#125;<br>        <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> self.test:<br>            rank = self.GetRecommendation(user)<br>            recs[user] = rank<br>        <span class="hljs-keyword">return</span> recs<br>        <br>    <span class="hljs-comment"># 定义精确率指标计算方式</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">precision</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">all</span>, hit = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> self.test:<br>            test_items = <span class="hljs-built_in">set</span>(self.test[user])<br>            rank = self.recs[user]<br>            <span class="hljs-keyword">for</span> item, score <span class="hljs-keyword">in</span> rank:<br>                <span class="hljs-keyword">if</span> item <span class="hljs-keyword">in</span> test_items:<br>                    hit += <span class="hljs-number">1</span><br>            <span class="hljs-built_in">all</span> += <span class="hljs-built_in">len</span>(rank)<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">round</span>(hit / <span class="hljs-built_in">all</span> * <span class="hljs-number">100</span>, <span class="hljs-number">2</span>)<br>    <br>    <span class="hljs-comment"># 定义召回率指标计算方式</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">recall</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">all</span>, hit = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> self.test:<br>            test_items = <span class="hljs-built_in">set</span>(self.test[user])<br>            rank = self.recs[user]<br>            <span class="hljs-keyword">for</span> item, score <span class="hljs-keyword">in</span> rank:<br>                <span class="hljs-keyword">if</span> item <span class="hljs-keyword">in</span> test_items:<br>                    hit += <span class="hljs-number">1</span><br>            <span class="hljs-built_in">all</span> += <span class="hljs-built_in">len</span>(test_items)<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">round</span>(hit / <span class="hljs-built_in">all</span> * <span class="hljs-number">100</span>, <span class="hljs-number">2</span>)<br>    <br>    <span class="hljs-comment"># 定义覆盖率指标计算方式</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">coverage</span>(<span class="hljs-params">self</span>):<br>        all_item, recom_item = <span class="hljs-built_in">set</span>(), <span class="hljs-built_in">set</span>()<br>        <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> self.test:<br>            <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> self.train[user]:<br>                all_item.add(item)<br>            rank = self.recs[user]<br>            <span class="hljs-keyword">for</span> item, score <span class="hljs-keyword">in</span> rank:<br>                recom_item.add(item)<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">round</span>(<span class="hljs-built_in">len</span>(recom_item) / <span class="hljs-built_in">len</span>(all_item) * <span class="hljs-number">100</span>, <span class="hljs-number">2</span>)<br>    <br>    <span class="hljs-comment"># 定义新颖度指标计算方式</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">popularity</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># 计算物品的流行度</span><br>        item_pop = &#123;&#125;<br>        <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> self.train:<br>            <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> self.train[user]:<br>                <span class="hljs-keyword">if</span> item <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> item_pop:<br>                    item_pop[item] = <span class="hljs-number">0</span><br>                item_pop[item] += <span class="hljs-number">1</span><br><br>        num, pop = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> self.test:<br>            rank = self.recs[user]<br>            <span class="hljs-keyword">for</span> item, score <span class="hljs-keyword">in</span> rank:<br>                <span class="hljs-comment"># 取对数，防止因长尾问题带来的被流行物品所主导</span><br>                pop += math.log(<span class="hljs-number">1</span> + item_pop[item])<br>                num += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">round</span>(pop / num, <span class="hljs-number">6</span>)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">eval</span>(<span class="hljs-params">self</span>):<br>        metric = &#123;<span class="hljs-string">&#x27;Precision&#x27;</span>: self.precision(),<br>                  <span class="hljs-string">&#x27;Recall&#x27;</span>: self.recall(),<br>                  <span class="hljs-string">&#x27;Coverage&#x27;</span>: self.coverage(),<br>                  <span class="hljs-string">&#x27;Popularity&#x27;</span>: self.popularity()&#125;<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Metric:&#x27;</span>, metric)<br>        <span class="hljs-keyword">return</span> metric<br></code></pre></td></tr></table></figure><h2 id="2-4-基于邻域的算法"><a href="#2-4-基于邻域的算法" class="headerlink" title="2.4 基于邻域的算法"></a>2.4 基于邻域的算法</h2><p>分为两种,基于<strong>用户</strong>的协同过滤算法和基于<strong>物品</strong>的协同过滤算法</p><h4 id="2-4-1-基于用户的协同过滤算法-UserCF"><a href="#2-4-1-基于用户的协同过滤算法-UserCF" class="headerlink" title="2.4.1 基于用户的协同过滤算法(UserCF)"></a>2.4.1 基于用户的协同过滤算法(UserCF)</h4><h5 id="1-基础算法"><a href="#1-基础算法" class="headerlink" title="1. 基础算法"></a>1. 基础算法</h5><p>两个步骤:</p><ol><li>找到和目标用户兴趣相似的用户集合</li><li>找到这个集合中用户喜欢的,且目标用户没听说过的物品推荐给目标用户</li></ol><p>步骤1的关键是计算两个用户的兴趣相似度,而协同算法主要利用行为的相似度计算兴趣的相似度.令$N(u)$表示用户$u$曾经有过正反馈的物品集合,$N(v)$为用户$v$曾经有过正反馈的物品集合.两者的用户相似度可通过下面的$Jaccard$公式计算:<br>$$<br>w_{uv}&#x3D;\frac{|N(u)\cap N(v)|}{|N(u)||N(v)|}<br>$$<br>也可通过余弦相似度计算:<br>$$<br>w_{uv}&#x3D;\frac{|N(u)\cap N(v)|}{\sqrt{|N(u)||N(v)|}}<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">UserSimilarity</span>(<span class="hljs-params">train</span>):<br>    W=<span class="hljs-built_in">dict</span>()<br>    <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> train.keys():<br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> train.keys():<br>            <span class="hljs-keyword">if</span> u==v:<br>                <span class="hljs-keyword">continue</span><br>            W[u][v]=<span class="hljs-built_in">len</span>(train[u]&amp;train[v])<br>            W[u][v]/=math.sqrt(<span class="hljs-built_in">len</span>(train[u])*<span class="hljs-built_in">len</span>(train[v])*<span class="hljs-number">1.0</span>)<br>    <span class="hljs-keyword">return</span> W<br></code></pre></td></tr></table></figure><p>这种计算相似度矩阵的方法时间复杂度为$O(|U|*|U|)$,然而大多数用户之间并没有共同购买的商品,即$|N(u)\cap N(v)|&#x3D;0$,这会加长计算时间.</p><p>下面这种计算相似度的算法首先建立物品到用户的<strong>倒查表</strong>,对于每个物品,保存对该物品产生过行为的<strong>用户列表</strong>.然后建立矩阵$C_{|U|\times |V|}$.该矩阵的每个元素代表两个用户间共同交互物品的个数,即$|N(u)\cap N(v)|$,可以先计算出$|N(u)\cap N(v)|\neq 0$的用户对$(u,v)$,然后再对这种情况除以$\sqrt{|N(u)||N(v)|}$.</p><div align=center><img src="https://hicgoal-img.oss-cn-beijing.aliyuncs.com/img/image-20220317171752948.png" alt="图2-7 物品-用户列表" style="zoom: 70%;" /></div><p>如上图,对于物品$a$,用户$A,B$都对其产生过行为,因此将$C[A][B]$和$C[B][A]$加1,以此类推.得到完整的$C$后,除以分母得到$W$.</p><p>得到用户间相似度矩阵$W$后,$\ UserCF$算法会给用户推荐和他兴趣最相似的$K$个用户喜欢的物品,用户$u$对物品$i$的感兴趣程度为:<br>$$<br>p(u,i)&#x3D;\sum_{v\in S(u,k)\cap N(i)}w_{uv}r_{vi}<br>$$<br>$S(u,k)$:与用户$u$兴趣最相似的$k$个人;    $N(i)$:对物品$i$感兴趣的用户集合</p><p>$w_{uv}$:$u,v$两个用户的兴趣相似度;    $r_{vi}$:用户$v$对物品$i$的感兴趣程度</p><p>因此,由上图可得:$\quad p(A,c)&#x3D;w_{AB}+w_{AD}&#x3D;0.7416\qquad p(A,e)&#x3D;w_{AC}+w_{AD}&#x3D;0.7416$</p><p>$UserCF$推荐算法的实现:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 3. 基于用户余弦相似度的推荐</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">UserCF</span>(<span class="hljs-params">train, K, N</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    :params: train, 训练数据集</span><br><span class="hljs-string">    :params: K, 超参数，设置取TopK相似用户数目</span><br><span class="hljs-string">    :params: N, 超参数，设置取TopN推荐物品数目</span><br><span class="hljs-string">    :return: GetRecommendation, 推荐接口函数</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># 计算item-&gt;user的倒排索引</span><br>    item_users = &#123;&#125;<br>    <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> train:<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> train[user]:<br>            <span class="hljs-keyword">if</span> item <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> item_users:<br>                item_users[item] = []<br>            item_users[item].append(user)<br>    <br>    <span class="hljs-comment"># 计算用户相似度矩阵</span><br>    sim = &#123;&#125;<br>    num = &#123;&#125;<br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> item_users:<br>        users = item_users[item]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(users)):<br>            u = users[i]<br>            <span class="hljs-keyword">if</span> u <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> num:<br>                num[u] = <span class="hljs-number">0</span><br>            num[u] += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> u <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> sim:<br>                sim[u] = &#123;&#125;<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(users)):<br>                <span class="hljs-keyword">if</span> j == i: <span class="hljs-keyword">continue</span><br>                v = users[j]<br>                <span class="hljs-keyword">if</span> v <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> sim[u]:<br>                    sim[u][v] = <span class="hljs-number">0</span><br>                sim[u][v] += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> sim:<br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> sim[u]:<br>            sim[u][v] /= math.sqrt(num[u] * num[v])<br>    <br>    <span class="hljs-comment"># 按照相似度排序</span><br>    sorted_user_sim = &#123;k: <span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(v.items(), \<br>                               key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)) \<br>                       <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> sim.items()&#125;<br>    <br>    <span class="hljs-comment"># 获取接口函数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">GetRecommendation</span>(<span class="hljs-params">user</span>):<br>        items = &#123;&#125;<br>        seen_items = <span class="hljs-built_in">set</span>(train[user])<br>        <span class="hljs-keyword">for</span> u, _ <span class="hljs-keyword">in</span> sorted_user_sim[user][:K]:<br>            <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> train[u]:<br>                <span class="hljs-comment"># 要去掉用户见过的</span><br>                <span class="hljs-keyword">if</span> item <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> seen_items:<br>                    <span class="hljs-keyword">if</span> item <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> items:<br>                        items[item] = <span class="hljs-number">0</span><br>                    items[item] += sim[user][u]<br>        recs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(items.items(), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>))[:N]<br>        <span class="hljs-keyword">return</span> recs<br>    <br>    <span class="hljs-keyword">return</span> GetRecommendation<br></code></pre></td></tr></table></figure><p>从$UserCF$的实验结果可得出以下结论:</p><ul><li>RS的精度指标$recall,precision$与$K$不是线性关系</li><li>$K$越大,推荐结果越热门(因为参考了更多人的意见)</li><li>$K$越大,覆盖率越低</li></ul><h5 id="2-用户相似度计算的改进"><a href="#2-用户相似度计算的改进" class="headerlink" title="2. 用户相似度计算的改进"></a>2. 用户相似度计算的改进</h5><p>两个用户对冷门物品采取过同样的行为更能说明他们兴趣的相似度（如果两个人都购买了《新华字典》，很难不能说明他们兴趣相似）。</p><p>$John\ S.\ Breese$提出:<br>$$<br>w_{uv}&#x3D;\frac{\sum_{i\in N(u)\cap N(v)}\frac{1}{log(1+|N(i)|)}}{\sqrt {|N(u)||N|v||}}<br>$$<br>即通过$\frac{1}{log1+|N(i)|}$惩罚用户$u$和$v$共同兴趣列表中热门物品对他们相似度的影响.</p><p>将其称为$User-IIF$算法:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 4. 基于改进的用户余弦相似度的推荐</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">UserIIF</span>(<span class="hljs-params">train, K, N</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    :params: train, 训练数据集</span><br><span class="hljs-string">    :params: K, 超参数，设置取TopK相似用户数目</span><br><span class="hljs-string">    :params: N, 超参数，设置取TopN推荐物品数目</span><br><span class="hljs-string">    :return: GetRecommendation, 推荐接口函数</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># 计算item-&gt;user的倒排索引 ...</span><br>    <span class="hljs-comment"># 计算用户相似度矩阵</span><br>    sim = &#123;&#125;<br>    num = &#123;&#125;<br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> item_users:<br>        users = item_users[item]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(users)):<br>            u = users[i]<br>            <span class="hljs-keyword">if</span> u <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> num:<br>                num[u] = <span class="hljs-number">0</span><br>            num[u] += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> u <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> sim:<br>                sim[u] = &#123;&#125;<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(users)):<br>                <span class="hljs-keyword">if</span> j == i: <span class="hljs-keyword">continue</span><br>                v = users[j]<br>                <span class="hljs-keyword">if</span> v <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> sim[u]:<br>                    sim[u][v] = <span class="hljs-number">0</span><br>                <span class="hljs-comment"># 相比UserCF，主要是改进了这里</span><br>                sim[u][v] += <span class="hljs-number">1</span> / math.log(<span class="hljs-number">1</span> + <span class="hljs-built_in">len</span>(users))<br>    <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> sim:<br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> sim[u]:<br>            sim[u][v] /= math.sqrt(num[u] * num[v])<br>    <br>    <span class="hljs-comment"># 按照相似度排序 ...</span><br>    <span class="hljs-comment"># 获取接口函数 ...</span><br>    <span class="hljs-keyword">return</span> GetRecommendation<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Experiment</span>():<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, M, K, N, fp=<span class="hljs-string">&#x27;../dataset/ml-1m/ratings.dat&#x27;</span>, rt=<span class="hljs-string">&#x27;UserCF&#x27;</span></span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        :params: M, 进行多少次实验</span><br><span class="hljs-string">        :params: K, TopK相似用户的个数</span><br><span class="hljs-string">        :params: N, TopN推荐物品的个数</span><br><span class="hljs-string">        :params: fp, 数据文件路径</span><br><span class="hljs-string">        :params: rt, 推荐算法类型</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        self.M = M<br>        self.K = K<br>        self.N = N<br>        self.fp = fp<br>        self.rt = rt<br>        self.alg = &#123;<span class="hljs-string">&#x27;Random&#x27;</span>: Random, <span class="hljs-string">&#x27;MostPopular&#x27;</span>: MostPopular, \<br>                    <span class="hljs-string">&#x27;UserCF&#x27;</span>: UserCF, <span class="hljs-string">&#x27;UserIIF&#x27;</span>: UserIIF&#125;<br>    <br>    <span class="hljs-comment"># 定义单次实验</span><br><span class="hljs-meta">    @timmer</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">worker</span>(<span class="hljs-params">self, train, test</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        :params: train, 训练数据集</span><br><span class="hljs-string">        :params: test, 测试数据集</span><br><span class="hljs-string">        :return: 各指标的值</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        getRecommendation = self.alg[self.rt](train, self.K, self.N)<br>        metric = Metric(train, test, getRecommendation)<br>        <span class="hljs-keyword">return</span> metric.<span class="hljs-built_in">eval</span>()<br>    <br>    <span class="hljs-comment"># 多次实验取平均</span><br><span class="hljs-meta">    @timmer</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">self</span>):<br>        metrics = &#123;<span class="hljs-string">&#x27;Precision&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;Recall&#x27;</span>: <span class="hljs-number">0</span>, <br>                   <span class="hljs-string">&#x27;Coverage&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;Popularity&#x27;</span>: <span class="hljs-number">0</span>&#125;<br>        dataset = Dataset(self.fp)<br>        <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.M):<br>            train, test = dataset.splitData(self.M, ii)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Experiment &#123;&#125;:&#x27;</span>.<span class="hljs-built_in">format</span>(ii))<br>            metric = self.worker(train, test)<br>            metrics = &#123;k: metrics[k]+metric[k] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> metrics&#125;<br>        metrics = &#123;k: metrics[k] / self.M <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> metrics&#125;<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Average Result (M=&#123;&#125;, K=&#123;&#125;, N=&#123;&#125;): &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(\<br>                              self.M, self.K, self.N, metrics))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 1. random实验</span><br>M, N = <span class="hljs-number">8</span>, <span class="hljs-number">10</span><br>K = <span class="hljs-number">0</span> <span class="hljs-comment"># 为保持一致而设置，随便填一个值</span><br>random_exp = Experiment(M, K, N, rt=<span class="hljs-string">&#x27;Random&#x27;</span>)<br>random_exp.run()<br><span class="hljs-comment"># 2. MostPopular实验</span><br>M, N = <span class="hljs-number">8</span>, <span class="hljs-number">10</span><br>K = <span class="hljs-number">0</span> <span class="hljs-comment"># 为保持一致而设置，随便填一个值</span><br>mp_exp = Experiment(M, K, N, rt=<span class="hljs-string">&#x27;MostPopular&#x27;</span>)<br>mp_exp.run()<br><span class="hljs-comment"># 3. UserCF实验</span><br>M, N = <span class="hljs-number">8</span>, <span class="hljs-number">10</span><br><span class="hljs-keyword">for</span> K <span class="hljs-keyword">in</span> [<span class="hljs-number">5</span>, <span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">40</span>, <span class="hljs-number">80</span>, <span class="hljs-number">160</span>]:<br>    cf_exp = Experiment(M, K, N, rt=<span class="hljs-string">&#x27;UserCF&#x27;</span>)<br>    cf_exp.run()<br><span class="hljs-comment"># 4. UserIIF实验</span><br>M, N = <span class="hljs-number">8</span>, <span class="hljs-number">10</span><br>K = <span class="hljs-number">80</span> <span class="hljs-comment"># 与书中保持一致</span><br>iif_exp = Experiment(M, K, N, rt=<span class="hljs-string">&#x27;UserIIF&#x27;</span>)<br>iif_exp.run()<br></code></pre></td></tr></table></figure><h5 id="关于实验的总结"><a href="#关于实验的总结" class="headerlink" title="关于实验的总结"></a><strong>关于实验的总结</strong></h5><ol><li><p>数据集分割的小技巧，用同样的seed</p></li><li><p>各个指标的实现，要注意</p></li><li><p>为每个用户推荐的时候是推荐他们****没有见过****的，因为测试集里面是这样的</p></li><li><p>倒排物品-用户索引，可进行时间优化</p></li><li><p>推荐的时候K和N各代表什么意思，要分开设置，先取TopK，然后取TopN</p></li></ol><p>$UserCF$存在的问题,随着网站的用户数增加,计算用户兴趣矩阵越来越困难,其运算空间复杂度和时间复杂度和用户数的增长近似于平方关系.其次,这种方法很难对推荐结果做出解释.</p><h4 id="2-4-2-基于物品的系统过滤算法-ItemCF"><a href="#2-4-2-基于物品的系统过滤算法-ItemCF" class="headerlink" title="2.4.2 基于物品的系统过滤算法(ItemCF)"></a>2.4.2 基于物品的系统过滤算法(ItemCF)</h4><p>目前业界应用最多的算法</p><h5 id="1-基础算法-1"><a href="#1-基础算法-1" class="headerlink" title="1. 基础算法"></a>1. 基础算法</h5><p>$ItemCF$给用户推荐那些和他们之前喜欢的物品相似的物品.但该算法<strong>并不利用</strong>物品的内容属性计算物品间的相似度,而是通过分析用户的行为记录来计算物品间的相似度.<strong>该算法认为,物品$A$和$B$具有很大的相似度是因为喜欢物品$A$的用户大都也喜欢物品$B$.</strong></p><p>同时该算法可以给推荐结果提供一个合理的解释,例如给用户推荐《深度学习》是因为该用户之前浏览过《机器学习》.</p><p>$ItemCF$算法主要分两步:</p><ol><li><p>计算物品间的相似度</p></li><li><p>利用物品间的相似度和用户的历史行为给用户生成推荐列表</p></li></ol><p><strong>物品相似度的定义:</strong></p><p>我们购物时常能看到”购买了该商品的用户也经常购买的其他物品”,实际上,物品的相似度定义也是如此,喜欢$i$的人中有多少喜欢$j$:<br>$$<br>w_{ij}&#x3D;\frac{|N(i)\cap N(j)|}{|N(i)|}<br>$$<br>$|N(i)|$是喜欢物品$i$的用户数,$|N(i)\cap N(j)|$是同时喜欢物品$i$和$j$的用户数.</p><p><strong>存在的问题</strong>:当$j$是热门商品时,$w_{ij}$接近1，即热门商品$j$和任意的商品$i$相似性都很高,会影响RS挖掘长尾信息.为了避免推荐出热门商品.可用下面的公式.<br>$$<br>w_{ij}&#x3D;\frac{|N(i)\cap N(j)|}{\sqrt{|N(i)||N(j)|}}<br>$$<br>这个公式惩罚了物品$j$的权重,减轻了热门物品会和很多物品相似的可能性.</p><p>从上面的定义可以看到，在协同过滤中两个物品产生相似度是因为它们共同被很多用户喜欢，也就是说每个用户都可以通过他们的历史兴趣列表给物品“贡献”相似度。这里面蕴涵着一个假设，就是每个用户的兴趣都局限在某几个方面，因此<strong>如果两个物品属于一个用户的兴趣列表，那么这两个物品可能就属于有限的几个领域，而如果两个物品属于很多用户的兴趣列表，那么它们就可能属于同一个领域，因而有很大的相似度.</strong></p><p>得到相似度后,通过以下公式计算用户$u$对一个物品$j$的兴趣:<br>$$<br>p_{uj}&#x3D;\sum_{i\in N(u)\cap S(j,k)}w_{ji}r_{ui}<br>$$<br>$r_{ui}$是用户对物品$i$的兴趣,$w_{ji}$是物品$j$与物品$i$的相似度.$N(u)$为用户$u$喜欢的物品集合,$S(j,k)$是与物品$j$最相似的$k$个物品</p><p>e.g.</p><div align=center><img src="https://hicgoal-img.oss-cn-beijing.aliyuncs.com/img/image-20220318205142800.png" alt="图2-12 一个简单的基于物品推荐的例子" style="zoom: 33%;" /></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 1. 基于物品余弦相似度的推荐</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ItemCF</span>(<span class="hljs-params">train, K, N</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    :params: train, 训练数据集</span><br><span class="hljs-string">    :params: K, 超参数，设置取TopK相似物品数目</span><br><span class="hljs-string">    :params: N, 超参数，设置取TopN推荐物品数目</span><br><span class="hljs-string">    :return: GetRecommendation, 推荐接口函数</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># 计算物品相似度矩阵</span><br>    sim = &#123;&#125;<br>    num = &#123;&#125;<br>    <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> train:<br>        items = train[user]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(items)):<br>            u = items[i]<br>            <span class="hljs-keyword">if</span> u <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> num:<br>                num[u] = <span class="hljs-number">0</span><br>            num[u] += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> u <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> sim:<br>                sim[u] = &#123;&#125;<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(items)):<br>                <span class="hljs-keyword">if</span> j == i: <span class="hljs-keyword">continue</span><br>                v = items[j]<br>                <span class="hljs-keyword">if</span> v <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> sim[u]:<br>                    sim[u][v] = <span class="hljs-number">0</span><br>                sim[u][v] += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> sim:<br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> sim[u]:<br>            sim[u][v] /= math.sqrt(num[u] * num[v])<br>    <br>    <span class="hljs-comment"># 按照相似度排序</span><br>    sorted_item_sim = &#123;k: <span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(v.items(), \<br>                               key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)) \<br>                       <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> sim.items()&#125;<br>    <br>    <span class="hljs-comment"># 获取接口函数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">GetRecommendation</span>(<span class="hljs-params">user</span>):<br>        items = &#123;&#125;<br>        seen_items = <span class="hljs-built_in">set</span>(train[user])<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> train[user]:<br>            <span class="hljs-keyword">for</span> u, _ <span class="hljs-keyword">in</span> sorted_item_sim[item][:K]:<br>                <span class="hljs-keyword">if</span> u <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> seen_items:<br>                    <span class="hljs-keyword">if</span> u <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> items:<br>                        items[u] = <span class="hljs-number">0</span><br>                    items[u] += sim[item][u]<br>        recs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(items.items(), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>))[:N]<br>        <span class="hljs-keyword">return</span> recs<br>    <br>    <span class="hljs-keyword">return</span> GetRecommendation<br></code></pre></td></tr></table></figure><p>实验结果显示:</p><ul><li>精度(准确率和召回率)$\quad ItemCF$推荐结果的精度与$K$不呈正相关或负相关</li><li>流行度$\quad$和$UserCF$不同,$k$对流行度的影响不是正相关的</li><li>覆盖率$\quad K$会降低系统的覆盖率</li></ul><h5 id="2-用户活跃度对物品相似度的影响"><a href="#2-用户活跃度对物品相似度的影响" class="headerlink" title="2. 用户活跃度对物品相似度的影响"></a>2. 用户活跃度对物品相似度的影响</h5><p>假设一个开书店的人买了当当网上80%的书,意味着由于这么一个用户,有80%的书两两之间产生了相似度,也就是说内存里会产生一个很大的稠密矩阵.除此之外.该用户买这些书并非出于自身的兴趣,而且这些书覆盖了很多领域,因此该用户对于他所购买的书的两两相似度的贡献应该远远小于只买了十几本自己喜欢的书的人.</p><p>依旧是$John\ S.\ Breese$提出了$IUF(Inverse\ User\ Frequence)$,即用户活跃度对数的倒数的参数,此时活跃用户对物品相似度的贡献应该小于不活跃的用户.$N(<em>)$表示用户$</em>$有兴趣的物品集合.<br>$$<br>w_{ij}&#x3D;\frac{\sum_{u\in N(i)\cap N(j)}\frac{1}{log(1+|N(u)|)}}{\sqrt {|N(i)||N|j||}}<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 只需要把上面的sim[u][v] += 1改为</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ItemIUF</span>(<span class="hljs-params">train, K, N</span>):<br>    <span class="hljs-comment"># ...</span><br>sim[u][v] += <span class="hljs-number">1</span> / math.log(<span class="hljs-number">1</span> + <span class="hljs-built_in">len</span>(items))<br>    <span class="hljs-comment"># ...</span><br></code></pre></td></tr></table></figure><p>在实际计算中,为了避免相似矩阵过于稠密,一般直接忽略该兴趣列表.</p><p>将这种算法记为$ItemCF-IUF$,实验结果显示它和$ItemCF$的精度类似,但提高了覆盖率,降低了准确度.</p><h5 id="3-物品相似度的归一化"><a href="#3-物品相似度的归一化" class="headerlink" title="3. 物品相似度的归一化"></a>3. 物品相似度的归一化</h5><p>将$ItemCF$的相似度矩阵按最大值归一化能够提高推荐的准确率,覆盖率和多样性.<br>$$<br>w_{ij}’&#x3D;\frac{w_{ij}}{\mathop{max}\limits_{j}\ w_{ij}}<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 3. 基于归一化的物品余弦相似度的推荐</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ItemCF_Norm</span>(<span class="hljs-params">train, K, N</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    :params: train, 训练数据集</span><br><span class="hljs-string">    :params: K, 超参数，设置取TopK相似物品数目</span><br><span class="hljs-string">    :params: N, 超参数，设置取TopN推荐物品数目</span><br><span class="hljs-string">    :return: GetRecommendation, 推荐接口函数</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># 计算物品相似度矩阵...    </span><br>    <span class="hljs-comment"># 对相似度矩阵进行按行归一化</span><br>    <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> sim:<br>        s = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> sim[u]:<br>            s += sim[u][v]<br>        <span class="hljs-keyword">if</span> s &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> sim[u]:<br>                sim[u][v] /= s<br>    <br>    <span class="hljs-comment"># 按照相似度排序 ...</span><br>    <span class="hljs-comment"># 获取接口函数 ...</span><br>    <span class="hljs-keyword">return</span> GetRecommendation<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 1. ItemCF实验</span><br>M, N = <span class="hljs-number">8</span>, <span class="hljs-number">10</span><br><span class="hljs-keyword">for</span> K <span class="hljs-keyword">in</span> [<span class="hljs-number">5</span>, <span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">40</span>, <span class="hljs-number">80</span>, <span class="hljs-number">160</span>]:<br>    cf_exp = Experiment(M, K, N, rt=<span class="hljs-string">&#x27;ItemCF&#x27;</span>)<br>    cf_exp.run()<br><span class="hljs-comment"># 2. ItemIUF实验</span><br>M, N = <span class="hljs-number">8</span>, <span class="hljs-number">10</span><br>K = <span class="hljs-number">10</span> <span class="hljs-comment"># 与书中保持一致</span><br>iuf_exp = Experiment(M, K, N, rt=<span class="hljs-string">&#x27;ItemIUF&#x27;</span>)<br>iuf_exp.run()<br><span class="hljs-comment"># 3. ItemCF-Norm实验</span><br>M, N = <span class="hljs-number">8</span>, <span class="hljs-number">10</span><br>K = <span class="hljs-number">10</span> <span class="hljs-comment"># 与书中保持一致</span><br>norm_exp = Experiment(M, K, N, rt=<span class="hljs-string">&#x27;ItemCF-Norm&#x27;</span>)<br>norm_exp.run()<br></code></pre></td></tr></table></figure><p>一般来说，物品总是属于很多不同的类，每一类中的物品联系比较紧密。假设在一个电影网站中，有两种电影——纪录片和动画片。那么，ItemCF算出来的相似度一般是纪录片和纪录片的相似度或者动画片和动画片的相似度大于纪录片和动画片的相似度。<strong>但是</strong>纪录片之间的相似度和动画片之间的相似度却不一定相同。假设物品分为两类——A和B，A类物品之间的相似度为0.5，B类物品之间的相似度为0.6，而A类物品和B类物品之间的相似度是0.2。在这种情况下，如果一个用户喜欢了5个A类物品和5个B类物品，用ItemCF给他进行推荐，推荐的就都是B类物品，因为B类物品之间的相似度大。但如果归一化之后，A类物品之间的相似度变成了1，B类物品之间的相似度也是1，那么这种情况下，用户如果喜欢5个A类物品和5个B类物品，那么他的推荐列表中A类物品和B类物品的数目也应该是大致相等的。从这个例子可以看出，相似度的归一化可以提高推荐的多样性。</p><p>那么，对于两个不同的类，什么样的类其类内物品之间的相似度高或者低?</p><p>一般来说，热门的类其类内物品相似度一般比较大。如果不进行归一化，就会推荐比较热门的类里面的物品，而这些物品也是比较热门的。因此，推荐的覆盖率就比较低。相反，如果进行相似度的归一化，则可以提高推荐系统的覆盖率。</p><p>实验结果显示归一化提高了ItemCF的各项指标。</p><h4 id="2-4-3-UserCF和ItemCF的比较"><a href="#2-4-3-UserCF和ItemCF的比较" class="headerlink" title="2.4.3 UserCF和ItemCF的比较"></a>2.4.3 UserCF和ItemCF的比较</h4><p>$UserCF$是推荐系统领域较为古老的算法，1992年就已经在电子邮件的个性化推荐系统Tapestry中得到了应用，1994年被GroupLens用来实现新闻的个性化推荐，后来被著名的文章分享网站Digg用来给用户推荐个性化的网络文章。ltemCF则是相对比较新的算法，在著名的电子商务网站亚马逊和DVD租赁网站Netflix中得到了广泛应用。为什么Digg使用UserCF，而亚马逊网使用ltemCF呢？<br>首先回顾一下UserCF算法和ItemCF算法的推荐原理。UserCF给用户推荐那些和他有共同兴趣爱好的用户喜欢的物品，而ItemCF给用户推荐那些和他之前喜欢的物品类似的物品。从这个算法的原理可以看到，UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点，而ItemCF的推荐结果着重于维系用户的历史兴趣。换句话说，UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ltemCF的推荐更加个性化，反映了用户自己的兴趣传承。</p><p>在新闻网站中，用户的兴趣不是特别细化，绝大多数用户都喜欢看热门的新闻。即使是个性化，也是比较粗粒度的，比如有些用户喜欢体育新闻，有些喜欢社会新闻，而特别细粒度的个性化一般是不存在的。比方说，很少有用户只看某个话题的新闻，主要是因为这个话题不可能保证每天都有新的消息，而这个用户却是每天都要看新闻的。因此，个性化新闻推荐更加强调抓住新闻热点，热门程度和时效性是个性化新闻推荐的重点，而个性化相对于这两点略显次要。因此，UserCF可以给用户推荐和他有相似爱好的一群其他用户今天都在看的新闻，这样在抓住热点和时效性的同时，保证了一定程度的个性化。这是Digg在新闻推荐中使用UserCF的最重要原因。</p><p>UserCF适合用于新闻推荐的另一个原因是从技术角度考量的。因为作为一种物品，新闻的更新非常快，每时每刻都有新内容出现，而ltemCF需要维护一张物品相关度的表，如果物品更新很快，那么这张表也需要很快更新，这在技术上很难实现。绝大多数物品相关度表都只能做到一天一次更新，这在新闻领域是不可以接受的。而UserCF只需要用户相似性表，虽然UserCF对于新用户也需要更新相似度表，但在新闻网站中，物品的更新速度远远快于新用户的加入速度，而且对于新用户，完全可以给他推荐最热门的新闻，因此UserCF显然是利大于弊。</p><p>但是，在图书、电子商务和电影网站，比如亚马逊、豆瓣、Netflix中，ItemCF则能极大地发挥优势。首先，在这些网站中，用户的兴趣是比较固定和持久的。一个技术人员可能都是在购买技术方面的书，而且他们对书的热门程度并不是那么敏感，事实上越是资深的技术人员，他们看的书就越可能不热门。此外，这些系统中的用户大都不太需要流行度来辅助他们判断一个物品的好坏，而是可以通过自己熟悉领域的知识自己判断物品的质量。因此，这些网站中个性化推荐的任务是帮助用户发现和他研究领域相关的物品。因此，ItemCF算法成为了这些网站的首选算法。</p><p>此外，这些网站的物品更新速度不会特别快，一天一次更新物品相似度矩阵对它们来说不会造成太大的损失，是可以接受的。</p><p>同时，从技术上考虑，UserCF需要维护一个用户相似度的矩阵，而ItemCF需要维护一个物品相似度矩阵。从存储的角度说，如果用户很多，那么维护用户兴趣相似度矩阵需要很大的空间，同理，如果物品很多，那么维护物品相似度矩阵代价较大。</p><p>在早期的研究中，大部分研究人员都是让少量的用户对大量的物品进行评价，然后研究用户兴趣的模式。那么，对于他们来说，因为用户很少，计算用户兴趣相似度是最快也是最简单的方法。但在实际的互联网中，用户数目往往非常庞大，而在图书、电子商务网站中，物品的数目则是比较少的。此外，物品的相似度相对于用户的兴趣一般比较稳定，因此使用ltemCF是比较好的选择。当然，新闻网站是个例外，在那儿，物品的相似度变化很快，物品数目庞大，相反用户兴趣则相对固定（都是喜欢看热门的），所以新闻网站的个性化推荐使用UserCF算法的更多。</p><p><img src="https://hicgoal-img.oss-cn-beijing.aliyuncs.com/img/image-20220319120621302.png" alt="image-20220319120621302"></p><p><strong>该实验结果显示:$ItemCF$算法的覆盖率和新颖度没$UserCF$高,下一节会介绍如何对前者进行改进.</strong></p><p>需要指出的是，离线实验的性能在选择推荐算法时并不起决定作用。首先应该满足产品的需求，比如如果需要提供推荐解释，那么可能得选择$ltemCF$算法。其次，需要看实现代价，比如若用户太多，很难计算用户相似度矩阵，这个时候可能不得不抛弃$UserCF$算法。最后，离线指标和点击率等在线指标不一定成正比。而且，这里对比的是最原始的$UserCF$和$ItemCF$算法，这两种算法都可以进行各种各样的改进。一般来说，这两种算法经过优化后，最终得到的离线性能是近似的。</p><h5 id="哈利波特问题-原始-ItemCF-算法的局限性"><a href="#哈利波特问题-原始-ItemCF-算法的局限性" class="headerlink" title="哈利波特问题(原始$ItemCF$算法的局限性)"></a>哈利波特问题(原始$ItemCF$算法的局限性)</h5><p>亚马逊网的研究人员在设计ItemCF算法之初发现ltemCF算法计算出的图书相关表存在一个问题，就是很多书都和《哈利波特》相关。也就是说，购买任何一本书的人似乎都会购买《哈利波特》。后来他们研究发现，主要是因为《哈利波特》太热门了，确实是购买任何一本书的人几乎都会购买它。</p><p>回顾:$ItemCF$之前采用的相似度计算公式尽管考虑到了$j$是热门商品会导致的问题,但在实际应用中,$j$依然会活得比较大的相似度.<br>$$<br>w_{ij}&#x3D;\frac{|N(i)\cap N(j)|}{\sqrt{|N(i)||N(j)|}}<br>$$<br><strong>解决方案1:</strong><br>$$<br>w_{ij}&#x3D;\frac{|N(i)\cap N(j)|}{|N(i)|^{1-\alpha}|N(j)|^\alpha} \qquad \alpha\in [0.5,1]<br>$$<br>通过提高$\alpha$,京可以惩罚热门的$j$,如果$\alpha&#x3D;0.5$就是标准的ItemCF算法.</p><p>离线实验结果显示，$\alpha&#x3D;0.5$时才会导致最高的准确率和召回率，而无论$\alpha&lt;0.5$或者$\alpha&gt;0.5$都不会带来这两个指标的提高。但是，$\alpha$越大，覆盖率就越高，并且结果的平均热门程度会降低。因此，通过这种方法可以在适当牺牲准确率和召回率的情况下显著提升结果的覆盖率和新颖性(降低流行度即提高了新颖性).</p><p><strong>解决方案2:</strong></p><p>不过，上述方法还不能彻底地解决哈利波特问题。每个用户一般都会在不同的领域喜欢一种物品。以电视为例，看新闻联播是父辈每天的必修课，他们每天基本就看新闻联播，而且每天不看别的新闻，就看这一种新闻。此外，他们很多都是电视剧迷，都会看央视一套8点的电视剧。那么，最终结果就是黄金时间的电视剧都和新闻联播相似，而新闻联播和其他新闻的相似度很低。<br>上面的问题换句话说就是，<strong>两个不同领域的最热门物品之间往往具有比较高的相似度。这个时候，仅仅靠用户行为数据是不能解决这个问题的，因为用户的行为表示这种物品之间应该相似度很高。</strong>此时，我们只能<strong>依靠引入物品的内容数据</strong>解决这个问题，比如<strong>对不同领域的物品降低权重</strong>等。这些就不是协同过滤讨论的范畴了。</p><h2 id="2-5-隐语义模型"><a href="#2-5-隐语义模型" class="headerlink" title="2.5 隐语义模型"></a>2.5 隐语义模型</h2><p>LFM(latent factor model)隐语义模型最早在文本挖掘领域被提出,用于找到文本的隐含语义.</p><h4 id="2-5-1-基础算法"><a href="#2-5-1-基础算法" class="headerlink" title="2.5.1 基础算法"></a>2.5.1 基础算法</h4><p>细节可以看<a href="https://zhuanlan.zhihu.com/p/108369470">这篇文章</a></p><p>核心思想是通过隐含特征(latent factor)联系用户兴趣和物品.与$UserCF$和$ItemCF$不同,这种方法不依赖于共同评分矩阵,他将用户和物品分别映射到某种真实含义未知的特征向量(也就是说向量每个维度的意义并不能人为给定).在预测时,对于任意一个空白评分的位置,就能通过两个向量的内积进行计算.</p><p>LFM通过下式计算用户$u$对物品$i$的兴趣:<br>$$<br>Preference(u,i)&#x3D;r_{ui}&#x3D;p_u^Tq_i&#x3D;\sum_{k&#x3D;1}^Kp_{u,k}\ q_{i,k}<br>$$<br>$p_{u,k}\ q_{i,k}$是模型的参数,前者度量了用户$u$的兴趣和第$k$个隐类的关系,而$q_{i,k}$度量了第$k$个隐类和物品$i$之间的关系.</p><p>这两个参数的计算需要学习一个训练集才能得到,而且这个训练集需要包含用户喜欢和不喜欢的物品.由于本章主要讨论的是隐性反馈数据集,因此需要生成负样本.</p><p>负样本采样一般需要遵循以下原则:</p><ul><li>对每个用户,要保证正负样本的均衡</li><li>对每个用户采样负样本时,要选取那些很热门,而用户却没有行为的物品</li></ul><p>一般认为,很热门而用户却没有行为更能说明用户对该商品不感兴趣.因为对于冷门的物品,用户可能没发现,所以谈不上是否感兴趣.</p><p>经过采样可以得到一个用户-物品集$K&#x3D;{ (u,i)}$,其中如果$(u,i)$是正样本,则有$r_{ui}&#x3D;1$,否则$r_{ui}&#x3D;0$,然后需要优化以下损失函数来找到最合适的参数$p$和$q$.<br>$$<br>C&#x3D;\sum_{(u,i)\in K}(r_{ui}-\hat r_{ui})^2&#x3D;\sum_{(u,i)\in K}\Big(r_{ui}-\sum_{k&#x3D;1}^Kp_{u,k}\ q_{i,k}\Big)^2+\lambda\Vert p_u \Vert^2+\lambda\Vert q_i \Vert^2<br>$$<br>$\lambda\Vert q_i \Vert^2$是用来防止过拟合的正则化项,$\ \lambda$可通过实验获得.<br>$$<br>\frac{\partial C}{\partial p_{uk}}&#x3D;-2q_{ik}+2\lambda p_{uk}\<br>\frac{\partial C}{\partial q_{ik}}&#x3D;-2p_{uk}+2\lambda q_{ik}\<br>\Rightarrow \<br>p_{uk}&#x3D;p_{uk}+\alpha(q_{ik}-\lambda p_{uk})\<br>q_{ik}&#x3D;q_{ik}+\alpha(p_{uk}-\lambda q_{ik})<br>$$<br>$\alpha$是学习率,为超参数,通过反复实验获得.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm, trange<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">LFM</span>(<span class="hljs-params">train, ratio, K, lr, step, lmbda, N</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    :params: train, 训练数据</span><br><span class="hljs-string">    :params: ratio, 负采样的正负比例</span><br><span class="hljs-string">    :params: K, 隐语义个数</span><br><span class="hljs-string">    :params: lr, 初始学习率</span><br><span class="hljs-string">    :params: step, 迭代次数</span><br><span class="hljs-string">    :params: lmbda, 正则化系数</span><br><span class="hljs-string">    :params: N, 推荐TopN物品的个数</span><br><span class="hljs-string">    :return: GetRecommendation, 获取推荐结果的接口</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <br>    all_items = &#123;&#125;<br>    <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> train:<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> train[user]:<br>            <span class="hljs-keyword">if</span> item <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> all_items:<br>                all_items[item] = <span class="hljs-number">0</span><br>            all_items[item] += <span class="hljs-number">1</span><br>    all_items = <span class="hljs-built_in">list</span>(all_items.items())<br>    items = [x[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> all_items]<br>    pops = [x[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> all_items]<br>    <br>    <span class="hljs-comment"># 负采样函数(注意！！！要按照流行度进行采样)</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">nSample</span>(<span class="hljs-params">data, ratio</span>):<br>        new_data = &#123;&#125;<br>        <span class="hljs-comment"># 正样本</span><br>        <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> data:<br>            <span class="hljs-keyword">if</span> user <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> new_data:<br>                new_data[user] = &#123;&#125;<br>            <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> data[user]:<br>                new_data[user][item] = <span class="hljs-number">1</span><br>        <span class="hljs-comment"># 负样本</span><br>        <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> new_data:<br>            seen = <span class="hljs-built_in">set</span>(new_data[user])<br>            pos_num = <span class="hljs-built_in">len</span>(seen)<br>            item = np.random.choice(items, <span class="hljs-built_in">int</span>(pos_num * ratio * <span class="hljs-number">3</span>), pops)<br>            item = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> item <span class="hljs-keyword">if</span> x <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> seen][:<span class="hljs-built_in">int</span>(pos_num * ratio)]<br>            new_data[user].update(&#123;x: <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> item&#125;)<br>        <br>        <span class="hljs-keyword">return</span> new_data<br>                <br>    <span class="hljs-comment"># 训练</span><br>    P, Q = &#123;&#125;, &#123;&#125;<br>    <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> train:<br>        P[user] = np.random.random(K)<br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> items:<br>        Q[item] = np.random.random(K)<br>            <br>    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> trange(step):<br>        data = nSample(train, ratio)<br>        <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> data:<br>            <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> data[user]:<br>                eui = data[user][item] - (P[user] * Q[item]).<span class="hljs-built_in">sum</span>()<br>                P[user] += lr * (Q[item] * eui - lmbda * P[user])<br>                Q[item] += lr * (P[user] * eui - lmbda * Q[item])<br>        lr *= <span class="hljs-number">0.9</span> <span class="hljs-comment"># 调整学习率</span><br>        <br>    <span class="hljs-comment"># 获取接口函数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">GetRecommendation</span>(<span class="hljs-params">user</span>):<br>        seen_items = <span class="hljs-built_in">set</span>(train[user])<br>        recs = &#123;&#125;<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> items:<br>            <span class="hljs-keyword">if</span> item <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> seen_items:<br>                recs[item] = (P[user] * Q[item]).<span class="hljs-built_in">sum</span>()<br>        recs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(recs.items(), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>))[:N]<br>        <span class="hljs-keyword">return</span> recs<br>    <br>    <span class="hljs-keyword">return</span> GetRecommendation<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># LFM实验(运行时间较长)</span><br>M, N = <span class="hljs-number">8</span>, <span class="hljs-number">10</span><br><span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">10</span>, <span class="hljs-number">20</span>]:<br>    exp = Experiment(M, N, ratio=r)<br>    exp.run()<br></code></pre></td></tr></table></figure><p>在LFM中,重要的参数有4个:</p><ul><li>隐特征的个数：$F$</li><li>学习率：$\alpha$</li><li>正则化参数：$\lambda$</li><li>负样本&#x2F;正样本比例：$ratio$</li></ul><p>在该实验中,$ratio&gt;10$以后,精度就比较稳定.同时随着负样本数目的增加,覆盖率不断降低,流行度升高.说明该参数控制了推荐算法挖掘长尾的能力.</p><p>当数据非常稀疏时,$LFM$性能会明显下降,甚至低于$UserCF$和$ItemCF$.</p><h4 id="2-5-2-基于LFM实际系统的例子"><a href="#2-5-2-基于LFM实际系统的例子" class="headerlink" title="2.5.2 基于LFM实际系统的例子"></a>2.5.2 基于LFM实际系统的例子</h4><p>Yahoo的研究人员以CTR为优化目标,利用LFM来预测用户是否会单机一个链接,他们将用户历史上对首页上链接的行为记录在作为训练集.</p><p>在新闻推荐中,冷启动问题问题很明显.每天都有大量新新闻,在很短的时间内得到和失去人们的关注.因此实时性很重要.</p><p>但LFM模型在实际使用中很难实现实时的推荐.经典的LFM模型每次训练都需要扫描所有的用户行为记录才能计算出用户隐类向量$p_u$和物品引隐类向量$q_i$,此外,训练也比较费时.实际中往往是一天训练一次.因此不能实时地调整推荐结果来满足用户最近的行为.</p><p>他们的解决方案分为两部分<br>$$<br>r_{ui}&#x3D;x_u^T\cdot y_i+p_u^T\cdot q_i<br>$$<br>用户向量$x_u$可以根据历史行为获得,每天只需计算一次.$y_i$根据物品的内容属性直接生成.$p_u$和$q_i$是根据实时拿到的用户最近几小时的行为训练LFM获得的.</p><p>因此对于一个新加入的物品$i$,可以通过$x_u^T\cdot y_i$估计用户$u$对物品$i$的兴趣,经过几小时后,就能通过$p_u^T\cdot q_i$得到更准确的预测值.</p><h4 id="2-5-3-LFM和基于邻域的方法的比较"><a href="#2-5-3-LFM和基于邻域的方法的比较" class="headerlink" title="2.5.3 LFM和基于邻域的方法的比较"></a>2.5.3 LFM和基于邻域的方法的比较</h4><ul><li><strong>理论基础</strong>    LFM有比较好的理论基础,通过优化设定目标建立最优模型;基于邻域的方法是一种基于统计的方法</li><li><strong>离线计算的空间复杂度</strong>    假设有$M$个用户和$N$个物品.在计算相关表的过程中可能会获得一张比较稠密的临时相关表,例如用户相关表$O(M \ast M)$或物品相关表$O(N\ast N)$,但$LFM$在建模过程中如果是$F$个隐类,那么需要的存储空间是$O(F\ast (M+N))$.</li><li><strong>离线计算的时间复杂度</strong>    假设有$M$个用户,$N$个物品,$K$条用户对物品的行为记录.$UserCF$的时间复杂度为$O(N\ast (K&#x2F;N)^2)$,$ItemCF$的时间复杂度为$O(M\ast (K&#x2F;M)^2)$.$LFM$如果用$F$个隐类,迭代$S$次,复杂度为$O(K\ast F\ast S)$一般情况下$LFM$会稍高一点,但无本质区别.</li><li><strong>在线实时推荐</strong>    $UserCF$和$ltemCF$在线服务算法需要将相关表缓存在内存中，然后可以在线进行实时的预测.$LFM$不能进行在线实时推荐，也就是说，当用户有了新的行为后，他的推荐列表不会发生变化。</li><li><strong>推荐解释</strong>    $ltemCF$算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果。但LFM无法提供这样的解释，它计算出的隐类虽然在语义上确实代表了一类兴趣和物品，却很难用自然语言描述并生成解释展现给用户。</li></ul><h2 id="2-6-基于图的模型"><a href="#2-6-基于图的模型" class="headerlink" title="2.6 基于图的模型"></a>2.6 基于图的模型</h2><p>用户行为很容易用二分图表示,因此很多图的算法都可以用到推荐系统中</p><h4 id="2-6-1-用户行为数据的二分图表示"><a href="#2-6-1-用户行为数据的二分图表示" class="headerlink" title="2.6.1 用户行为数据的二分图表示"></a>2.6.1 用户行为数据的二分图表示</h4><p>令$G(V,E)$表示用户物品二分图,$V&#x3D;V_U\cup V_I$由用户顶点集合$V_U$和物品顶点集合$V_I$组成.对于数据集每一个二元组$(u,i)$,图中都有一套对应的边$e(v_u,v_i)$.图2-18是一个用户物品二分图模型,圆形节点代表用户,方形代表物品,边表示用户对物品的行为.</p><div align=center><img src="https://hicgoal-img.oss-cn-beijing.aliyuncs.com/img/image-20220319183843603.png" alt="图2-18 用户物品二分图模型" style="zoom:50%;" /></div><h4 id="2-6-2-基于图的推荐算法"><a href="#2-6-2-基于图的推荐算法" class="headerlink" title="2.6.2 基于图的推荐算法"></a>2.6.2 基于图的推荐算法</h4><p>此时给用户$u$推荐物品的任务可以转化为度量用户顶点$v_u$和与$v_u$没有边直接相连的物品节点在图上的相关性,相关性越高的物品在推荐列表中的权重就越高.</p><p>图中<strong>顶点的相关性主要取决于下面三个因素:</strong></p><ul><li>两个顶点之间的路径数；</li><li>两个顶点之间路径的长度；</li><li>两个顶点之间的路径经过的顶点.</li></ul><p>而<strong>相关性高的一对顶点一般具有如下特征：</strong></p><ul><li>两个顶点之间有很多路径相连；</li><li>连接两个顶点之间的路径长度都比较短；</li><li>连接两个顶点之间的路径不会经过出度比较大的顶点.</li></ul><p>以下图为例;</p><div align=center><img src="https://hicgoal-img.oss-cn-beijing.aliyuncs.com/img/image-20220319191551064.png" alt="图2-19 基于图的推荐算法示例" style="zoom: 50%;" /></div><p>用户A和物品c、e没有边相连，但是用户A和物品c有一条长度为3的路径相连，用户A和物品e有两条长度为3的路径相连。那么，顶点A与e之间的相关性要高于顶点A与c，因而物品e在用户A的推荐列表中应该排在物品c之前，因为顶点A与e之间有两条路径——(A,b,C,e)和(A,d,D,e).其中,(A,b,C,e)路径经过的顶点的出度为(3,2,2,2)而(A,d,D,e)路径经过的顶点的出度为(3,2,3,2)。因此,(A,d,D,e)经过了一个出度比较大的顶点D，所以(A,d,D,e)对顶点A与e之间相关性的贡献要小于(A,b,C,e).</p><p>基于上面三个主要因素,有很多计算图中顶点之间相关性的方法,如基于随机游走的$PersonalRank$算法.</p><h5 id="PersonalRank-算法"><a href="#PersonalRank-算法" class="headerlink" title="$PersonalRank$算法"></a>$PersonalRank$算法</h5><p>假设要给用户$u$进行个性化推荐，可以从用户$u$对应的节点$v_u$开始,在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率$\alpha$决定是继续游走，还是停止这次游走并从$v_u$节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照<strong>均匀分布</strong>随机选择一个节点作为游走下次经过的节点。这样，经过很多次随机游走后，每个物品节点被访问到的概率会<strong>收敛到一个数</strong>。最终的推荐列表中物品的权重就是物品节点的访问概率。<br>如果将上面的描述表示成公式，可以得到如下公式：</p><div align=center><img src="https://hicgoal-img.oss-cn-beijing.aliyuncs.com/img/image-20220319200225631.png" alt="" style="zoom: 50%;" /></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">PersonalRank</span>(<span class="hljs-params">train, alpha, N</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    :params: train, 训练数据</span><br><span class="hljs-string">    :params: alpha, 继续随机游走的概率</span><br><span class="hljs-string">    :params: N, 推荐TopN物品的个数</span><br><span class="hljs-string">    :return: GetRecommendation, 获取推荐结果的接口</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span> <br>    <br>    <span class="hljs-comment"># 构建索引</span><br>    items = []<br>    <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> train:<br>        items.extend(train[user])<br>    id2item = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(items))<br>    users = &#123;u: i <span class="hljs-keyword">for</span> i, u <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train.keys())&#125;<br>    items = &#123;u: i+<span class="hljs-built_in">len</span>(users) <span class="hljs-keyword">for</span> i, u <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(id2item)&#125;<br>    <br>    <span class="hljs-comment"># 计算转移矩阵（注意！！！要按照出度进行归一化）</span><br>    item_user = &#123;&#125;<br>    <span class="hljs-keyword">for</span> user <span class="hljs-keyword">in</span> train:<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> train[user]:<br>            <span class="hljs-keyword">if</span> item <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> item_user:<br>                item_user[item] = []<br>            item_user[item].append(user)<br>            <br>    data, row, col = [], [], []<br>    <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> train:<br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> train[u]:<br>            data.append(<span class="hljs-number">1</span> / <span class="hljs-built_in">len</span>(train[u]))<br>            row.append(users[u])<br>            col.append(items[v])<br>    <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> item_user:<br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> item_user[u]:<br>            data.append(<span class="hljs-number">1</span> / <span class="hljs-built_in">len</span>(item_user[u]))<br>            row.append(items[u])<br>            col.append(users[v])<br>            <br>    M = csc_matrix((data, (row, col)), shape=(<span class="hljs-built_in">len</span>(data), <span class="hljs-built_in">len</span>(data)))<br>    <br>    <span class="hljs-comment"># 获取接口函数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">GetRecommendation</span>(<span class="hljs-params">user</span>):<br>        seen_items = <span class="hljs-built_in">set</span>(train[user])<br>        <span class="hljs-comment"># 解矩阵方程 r = (1-a)r0 + a(M.T)r</span><br>        r0 = [<span class="hljs-number">0</span>] * <span class="hljs-built_in">len</span>(data)<br>        r0[users[user]] = <span class="hljs-number">1</span><br>        r0 = csc_matrix(r0)<br>        r = (<span class="hljs-number">1</span> - alpha) * linalg.inv(eye(<span class="hljs-built_in">len</span>(data)) - alpha * M.T) * r0<br>        r = r.T.toarray()[<span class="hljs-number">0</span>][<span class="hljs-built_in">len</span>(users):]<br>        idx = np.argsort(-r)[:N]<br>        recs = [(id2item[ii], r[ii]) <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> idx]<br>        <span class="hljs-keyword">return</span> recs<br>    <br>    <span class="hljs-keyword">return</span> GetRecommendation<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># PersonalRank实验</span><br>M, N, alpha = <span class="hljs-number">8</span>, <span class="hljs-number">10</span>, <span class="hljs-number">0.8</span><br>exp = Experiment(M, N, alpha)<br>exp.run()<br></code></pre></td></tr></table></figure><p>$PersonalRank$算法有较好的理论解释,但算法复杂度很高.因为在为每个用户进行推荐时，都需要在整个用户物品二分图上进行迭代，直到整个图上的每个顶点的$PR$值收敛。这一过程的时间复杂度非常高，不仅无法在线提供实时推荐，甚至离线生成推荐结果也很耗时。</p><p>解决方案一:减少迭代次数，在收敛之前就停止。这样会影响最终的精度，但一般来说影响不会特别大。</p><p>解决方案二:将$PersonalRank$转化为矩阵的形式。令$M$为用户物品二分图的转移概率矩阵，即：<br>$$<br>M(v,v’)&#x3D;\frac{1}{|out(v)|}<br>$$<br>迭代公式可转化为:<br>$$<br>r&#x3D;(1-\alpha)r_0+\alpha M^T&#x3D;(1-\alpha)(1-\alpha M^T)^{-1}r_0<br>$$<br>这时只需利用稀疏矩阵快速求逆的办法来计算$(1-\alpha M^T)^{-1}$即可.</p>]]></content>
    
    
    
    <tags>
      
      <tag>读书笔记</tag>
      
      <tag>推荐系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>推荐系统实践（项亮）第一章笔记</title>
    <link href="/2022/03/16/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%EF%BC%88%E9%A1%B9%E4%BA%AE%EF%BC%89%E7%AC%AC%E4%B8%80%E7%AB%A0/"/>
    <url>/2022/03/16/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%EF%BC%88%E9%A1%B9%E4%BA%AE%EF%BC%89%E7%AC%AC%E4%B8%80%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="第一章-好的推荐系统"><a href="#第一章-好的推荐系统" class="headerlink" title="第一章 好的推荐系统"></a>第一章 好的推荐系统</h1><h2 id="1-1-什么是推荐系统"><a href="#1-1-什么是推荐系统" class="headerlink" title="1.1 什么是推荐系统"></a>1.1 什么是推荐系统</h2><p>以看电影为例：</p><p>社会化推荐：找朋友问，发布动态等待热心人评论。既让好友给自己推荐物品。</p><p>基于内容的推荐：输入喜欢的演员名，发现没看过的就去观看。这种方式是寻找和自己之前看过的在内容上相似的电影。推荐系统可以将上述过程自动化，通过分析用户的喜欢的导演、演员等，然后给用户推荐相关电影。</p><p>基于协同过滤的推荐：看看别人都在看什么，找一部广受好评的进行观看。即找到和自己历史兴趣相似的一群用户，这样的结果可能比宽泛的热门排行榜更能符合自己的兴趣。</p><p>因此，推荐算法的本质是通过一定的方式将用户和物品联系起来，而不同的推荐系统利用了不同的方式。如图1-2展示了三种方式。</p><div align=center><img src="https://hicgoal-img.oss-cn-beijing.aliyuncs.com/img/image-20220316150237617.png" alt="图1-2 推荐系统常用的3种联系用户和物品的方式" style="zoom:50%;" /></div><h2 id="1-2-个性化推荐系统的应用"><a href="#1-2-个性化推荐系统的应用" class="headerlink" title="1.2 个性化推荐系统的应用"></a>1.2 个性化推荐系统的应用</h2><p>与搜索引擎不同，个性化推荐系统组要依赖用户的行为数据，因此一般是作为一个应用存在于不同的网站中。其通过大量分析用户日志进而提供给用户不同的个性化页面展示，来提高网站的CTR和CVR。</p><p>广泛应用RS的领域包括电子商务，阅读，音乐，个性化邮件和广告等。但总的来说，<strong>几乎所有的推荐系统都是由前台的展示页面、后台的日志系统、以及推荐算法系统3部分构成。</strong>下面围绕这三个方面对不同的个性化推荐系统应用进行介绍。</p><hr><p>　　CVR (Click Value Rate): 转化率，衡量CPA广告效果的指标<br>　　CTR (Click Through Rate): 点击率<br>　　CPC (Cost Per Click): 按点击计费<br>　　CPA (Cost Per Action): 按成果数计费<br>　　CPM (Cost Per Mille): 按千次展现计费<br>　　PV (Page View): 流量<br>　　PV单价: 每PV的收入，衡量页面流量变现能力的指标<br>　　ADPV (Advertisement Page View): 载有广告的pageview流量<br>　　ADimp (ADimpression): 单个广告的展示次数<br>　　RPS (Revenue Per Search): 每搜索产生的收入，衡量搜索结果变现能力指标<br>　　ROI：投资回报率(ROI)是指通过投资而应返回的价值，它涵盖了企业的获利目标。利润和投入的经营所必备的财产相关，因为管理人员必须通过投资和现有财产获得利润。又称会计收益率、投资利润率。</p><hr><h3 id="1-2-1-电子商务"><a href="#1-2-1-电子商务" class="headerlink" title="1.2.1 电子商务"></a>1.2.1 电子商务</h3><p>以亚马逊的推荐系统为例，最主要的应用有<strong>个性化商品推荐列表</strong>和<strong>相关商品的推荐列表</strong>。</p><p>个性化推荐列表（两种）：</p><ul><li>基于物品的推荐算法，给用户推荐那些和他们之前喜欢的物品相似的物品</li><li>按照用户在脸书上的好友关系，给用户推荐他们好友在亚马逊上喜欢的物品</li></ul><p>相关推荐列表（两种）：</p><ul><li>买了这个商品的用户也经常购买的其他商品</li><li>浏览过这个商品的用户经常购买的其他用品</li></ul><p>两者使用了不同用户行为计算物品的相关性。此外。会让你选择是否同时购买，他会把这几件商品“打包”，同时可能会提供折扣。这种销售手段是推荐算法最重要的应用。</p><h3 id="1-2-2-电影和视频网站"><a href="#1-2-2-电影和视频网站" class="headerlink" title="1.2.2 电影和视频网站"></a>1.2.2 电影和视频网站</h3><p>…</p><h3 id="1-2-8-个性化广告"><a href="#1-2-8-个性化广告" class="headerlink" title="1.2.8 个性化广告"></a>1.2.8 个性化广告</h3><p>个性化广告投放目前已经成为了一们独立的学科——计算广告学——该学科和推荐系统在很多基础理论和方法上是相通的，比如他们的目的都是联系用户和物品，只是在个性化广告中，物品就是广告。</p><p>个性化广告投放和狭义个性化推荐的区别是，个性化推荐着重于帮助用户找到可能令他们感兴趣的物品，而广告推荐着重于帮助广告找到可能对它们感兴趣的用户，即一个是以用户为核心，而另一个以广告为核心。目前的个性化广告投放技术主要分为3种。</p><ul><li><strong>上下文广告</strong>$\quad$通过分析用户正在浏览的网页内容，投放和网页内容相关的广告。</li><li><strong>搜索广告</strong>$\quad$通过分析用户在当前会话中的搜索记录，判断用户的搜索目的，投放和用户目的相关的广告。</li><li><strong>个性化展示广告</strong>$\quad$我们经常在很多网站看到大量展示广告（就是那些大的横幅图片），它们是根据用户的兴趣，对不同用户投放不同的展示广告。雅虎是这方面研究的代表。</li></ul><h2 id="1-3-推荐系统评测"><a href="#1-3-推荐系统评测" class="headerlink" title="1.3 推荐系统评测"></a>1.3 推荐系统评测</h2><p>什么才是好的推荐系统？这是推荐系统评测需要解决的首要问题。一个完整的推荐系统一般存在3个参与方（如图1-22所示）：<strong>用户、物品提供者和提供推荐系统的网站</strong>。</p><p>以图书推荐为例，首先，推荐系统需要满足用户的需求，给用户推荐那些令他们感兴趣的图书。其次，推荐系统要让各出版社的书都能够被推荐给对其感兴趣的用户，而不是只推荐几个大型出版社的书。最后，好的推荐系统设计，能够让推荐系统本身收集到高质量的用户反馈，不断完善推荐的质量，增加用户和网站的交互，提高网站的收入。</p><p>因此在评测一个推荐算法时，需要同时考虑三方的利益，一个好的推荐系统是能够令三方共赢的系统。</p><p>需要注意的是，<strong>做出准确预测的推荐系统并不意味着好的推荐系统</strong>。假如一个图书推荐系统预测一个用户将来会购买《C++Primer中文版》这本书，而用户后来确实均买了，那么这就被看做一次准确的预测。<strong>预测准确度</strong>是推荐系统领域的重要指标（没有之一）。这个指标的好处是，它可以<strong>比较容易地通过离线方式计算出来</strong>，<strong>从而方便研究人员快速评价和选择不同的推荐算法。</strong>但是，很多研究表明，准确的预测并不代表好的推荐。比如说，该用户早就准备买《C++Primer中文版》了，无论是否给他推荐，他都准备购买，那么这个推荐结果显然是不好的，因为它并未使用户购买更多的书，而仅仅是方便用户购买一本他本来就准备买的书。</p><p>那么，对于用户来说，他会觉得这个推荐结果很不新颖，不能令他惊喜。同时，对于《C++Primer中文版》的出版社来说，这个推荐也没能增加这本书的潜在购买人数。所以，这是一个看上去很好，但其实却很失败的推荐。举一个更极端的例子，某推测系统预测明天太阳将从东方升起，虽然预测准确率是100%，却是一种没有意义的预测。</p><p>好的推荐系统不仅仅能够准确预测用户的行为，还能帮助用户发现那些他们可能会感兴趣，但却不那么容易发现的东西。同时，推荐系统还要能够<strong>帮助商家</strong>将那些被埋没在长尾中的好商品介绍给可能会对它们感兴趣的用户。</p><p>为了全面评测推荐系统对三方利益的影响，本章将从不同角度出发，提出不同的指标。这些指标包括<strong>准确度、覆盖度、新颖度、惊喜度、信任度、透明度等</strong>。这些指标中，有些可以离线计算，有些只有在线才能计算，有些只能通过用户问卷获得。下面各节将会依次介绍这些指标的出发点、含义，以及一些指标的计算方法。</p><h3 id="1-3-1-推荐系统实验方法"><a href="#1-3-1-推荐系统实验方法" class="headerlink" title="1.3.1 推荐系统实验方法"></a>1.3.1 推荐系统实验方法</h3><p>三种评测推荐效果的实验方法：</p><ul><li>离线实验（offline experiment）</li><li>用户调查（user study）</li><li>在线实验（online experiment）</li></ul><h4 id="1-离线实验"><a href="#1-离线实验" class="headerlink" title="1. 离线实验"></a>1. 离线实验</h4><p>   离线实验一般由以下几个步骤构成：</p><p>   (1) 通过日志系统获得用户行为数据，并按照一定格式生成一个表针的数据集</p><p>   (2) 将数据按规则分为训练集和测试集</p><p>   (3) 在训练集上训练用户兴趣模型，在测试集上进行预测</p><p>   (4) 通过事先定义的离线指标评测算法在测试集上的预测结果</p><p>​        从上面的步骤可以看到，推荐系统的<strong>离线实验都是在数据集上完成的</strong>，也就是说它<strong>不需要一个实际的系统来供它实验</strong>，而只要有一个从实际系统日志中提取的数据集即可。这种实验方法的<strong>好处是不需要真实用户参与</strong>，<strong>可以直接快速地计算出来，从而方便、快速地测试大量不同的算法。</strong>主要缺点是无法获得很多商业上关注的指标，如点击率、转化率等，而找到和商业指标非常相关的离线指标也是很困难的事情。表1-2简单总结了离线实验的优缺点点。</p><div align=center><img src="https://hicgoal-img.oss-cn-beijing.aliyuncs.com/img/image-20220316150237617.png" alt="图1-2 推荐系统常用的3种联系用户和物品的方式" style="zoom:50%;" /></div><table><thead><tr><th align="center">优点</th><th align="center">缺点</th></tr></thead><tbody><tr><td align="center">不需要对实际系统的控制权</td><td align="center">无法计算商业上关心的指标</td></tr><tr><td align="center">不需要用户参与实验</td><td align="center">离线实验的指标和商业指标存在差距</td></tr><tr><td align="center">速度快</td><td align="center"></td></tr></tbody></table><h4 id="2-用户调查"><a href="#2-用户调查" class="headerlink" title="2. 用户调查"></a>2. 用户调查</h4><p>​        离线实验的指标和实际的商业指标存在差距，如预测准确率和用户满意度。因此<strong>准确评测算法需要相对比较真实的环境</strong>，最好的方法就是将算法直接上线测试，但可能会降低用户满意度，因此在上线前需要做一次成为用户调查的测试。</p><p>​        用户调查需要有一些<strong>真实用户</strong>，让他们在需要测试的推荐系统上完成一些任务。在他们完成任务时，我们需要观察和记录他们的行为，并让他们回答一些问题。最后，我们需要通过分析他们的行为和答案了解测试系统的性能。离线时没有办法评测的与用户主观感受有关的指标都可以通过用户调查获得。</p><p>​        <strong>缺点：</strong>成本很高，很难进行大规模的用户调查，人数较少的用户调查，往往没有统计意义。此外，需要尽量保证测试用户的分布和真实用户的<strong>分布相同</strong>，比如男女各半，以及年龄、活跃度的分布都和真实用户分布尽量相同。用户调查要尽量保证是<strong>双盲实验</strong>，不要让实验人员和用户事先知道测试目标，以免测试受主观成分的影响。（在很多时候设计双盲实验非常困难，因而在测试环境下收集的测试指标可能在真实环境下无法重现。）<br>       <strong>优点：</strong>可以获得体现用户主观感受的指标，在线实验风险很低，出现错误后很容易弥补。</p><h4 id="3-在线实验"><a href="#3-在线实验" class="headerlink" title="3. 在线实验"></a>3. 在线实验</h4><p>​        完成离线实验和用户调查后,可将推荐系统上线做<strong>AB测试</strong>,将其和旧的算法进行比较</p><p>​        <strong>AB测试</strong>是一种<strong>在线评测算法</strong>的实验方法,通过一定规则将用户随机分为几组,不同组采用不同算法,进而统计各自的评测指标来比较不同算法.</p><p>​        **优点:**可公平获得不同算法实际在显示的性能指标</p><p>​        **缺点:**周期过长,需要长期实验才能得到可靠的结果.因此一般只会用AB测试测试在离线实验和用户调查中表现很好的算法.同时考虑这样一种情况,对于一个大型网站,其前端和后端由不同团队控制,可能进行一个后台推荐算法AB测试时网页团队在做推荐页面的界面AB测试.因此,切分流量是AB测试中的关键，不同的层以及控制这些层的团队需要从一个统一的地方获得自己AB测试的流量，而不同层之间的流量应该是正交的。</p><p>​        图1-23是一个简单的AB测试系统,用户进入网站后，流量分配系统决定用户是否需要被进行AB测试，如果需要的话，流量分配系统会给用户打上在测试中属于什么分组的标签。然后用户浏览网页，而用户在浏览网页时的行为都会被通过日志系统发回后台的日志数据库。此时，如果用户有测试分组的标签，那么该标签也会被发回后台数据库。</p><p>​        在后台，实验人员的工作首先是配置流量分配系统，决定满足什么条件的用户参加什么样的测试。其次，实验人员需要统计日志数据库中的数据，通过评测系统生成不同分组用户的实验报告，并比较和评测实验结果。</p><div align=center><img src="https://hicgoal-img.oss-cn-beijing.aliyuncs.com/img/image-20220314215941918.png" alt="图1-23AB测试系统" style="zoom: 67%;" /></div><p>​        一般来说,一个新的推荐系统最终上线,需要完成上面所说的三个实验:</p><ul><li>通过<strong>离线实验</strong>证明它在很多<strong>离线指标</strong>上优于现有的算法</li><li>通过<strong>用户调查</strong>确定它的<strong>用户满意度</strong>不低于现有的算法</li><li>通过在线的<strong>AB测试</strong>确定它在我们<strong>关心的指标</strong>上优于现有的算法</li></ul><h3 id="1-3-2-评测指标"><a href="#1-3-2-评测指标" class="headerlink" title="1.3.2 评测指标"></a>1.3.2 评测指标</h3><h4 id="1-用户满意度"><a href="#1-用户满意度" class="headerlink" title="1.用户满意度"></a>1.用户满意度</h4><p>​        无法离线计算,只能通过用户调查或在线实验获得.</p><p>​        用户调查获得用户满意度一般是通过调查问卷的形式,问卷的设计不是简单的满意&#x2F;不满意,应考虑到各个感受.</p><p>​        在线系统中,用户满意度主要通过对用户行为的统计得到.例如电商网站中,购买率可以度量用户的满意度.或者是设计用户反馈页面手机用户满意度,如bilibili下的不感兴趣.</p><p>​        更一般的情况,可以用CTR,用户停留时间和转化率等指标度量用户的满意度.</p><h4 id="2-预测准确度"><a href="#2-预测准确度" class="headerlink" title="2. 预测准确度"></a>2. 预测准确度</h4><p>​        度量一个推荐系统或者推荐算法<strong>预测用户行为的能力</strong>,是<strong>最重要的系统离线评测指标</strong>,大多数paper讨论的也是这个指标(可通过离线实验计算,方便研究员研究推荐算法)</p><p>​        计算该指标需要一个离线的数据集,通过在训练集上建立用户的行为和兴趣模型预测用户在测试集上行为.</p><p>​        离线的推荐算法有不同的研究方向,下面为不同的研究方向对应的预测准确度指标.</p><ul><li><strong>评分预测</strong></li></ul><p>学习用户的历史评分,进而预测其在将来看到一个他没有评过分的物品时,会给这个物品评多少分.</p><p>评分预测的预测准确度一般通过均方根误差 (RMSE) 和平均绝对误差 (MAE) 计算.对于测试集$T$中的一个用户$u$和物品$i$,令$r_{ui}$代表用户对物品的实际评分,令$\hat{r}_{ui}$为预测评分.</p><ul><li>RMSE定义为：</li></ul><p>$$<br>RMSE&#x3D;\sqrt{\frac{\sum_{u,i\in T}(r_{ui}-\hat{r_{ui})^2}}{|T|}}<br>$$</p><ul><li>MAE采用绝对值计算预测误差，其定义为：</li></ul><p>$$<br>MAE&#x3D;\frac{\sum_{u,i\in T}|r_{ui}-\hat r_{ui}|}{|T|}<br>$$</p><p>​        假设用一个列表<code>records</code>存放用户评分数据,令<code>records[i]=[u,i,rui,pui]</code>,后两者分别为实际和预测得分,则下面的代码实现了RMSE和MAE的计算过程</p><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">RMSE</span>(<span class="hljs-params">records</span>):<br><span class="hljs-keyword">return</span> math.sqrt(<span class="hljs-built_in">sum</span>([(rui-pui)*(rui-pui) <span class="hljs-keyword">for</span> u,i,rui,pui <span class="hljs-keyword">in</span> records])/<span class="hljs-built_in">float</span>(<span class="hljs-built_in">len</span>(records)))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">MAE</span>(<span class="hljs-params">records</span>):<br><span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>([<span class="hljs-built_in">abs</span>(rui-pui) <span class="hljs-keyword">for</span> u,i,rui,pui <span class="hljs-keyword">in</span> records])/<span class="hljs-built_in">float</span>(<span class="hljs-built_in">len</span>(records))<br></code></pre></td></tr></table></figure><p>​        关于这两个指标的优缺点:</p><p>​        RMSE加大了对预测不准的用户物品评分的惩罚,因而对系统的评测更加苛刻</p><p>小tips:如果评分系统是基于整数建立的(即用户给的评分都是整数),那么对预测结果取整会降低MAE的误差.</p><ul><li>TopN推荐</li></ul><p>​        网站在提供推荐服务时,一般是给用户一个<strong>个性化的推荐列表</strong>,这种推荐叫做TopN推荐.其预测准确率一般通过准确率(precision)&#x2F;召回率(recall)度量.<br>​        令$R(u)$是根据用户在训练集上的行为给用户作出的推荐列表,$T(u)$是用户在测试集上的行为列表,那么推荐结果的召回率定义为:<br>$$<br>Recall&#x3D;\frac{\sum_{u\in U}|R(U)\cap T(U)|}{\sum_{u\in U}T(U)}<br>$$<br>​        推荐结果的准确率定义为:<br>$$<br>Precision&#x3D;\frac{\sum_{u\in U}|R(U)\cap T(U|}{\sum_{u\in U}R(U)}<br>$$<br>​        代码实现:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">PrecisionRecall</span>(<span class="hljs-params">test,N</span>):<br>    hit = <span class="hljs-number">0</span><br>    n_recall=<span class="hljs-number">0</span><br>    n_precision=<span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> user,items <span class="hljs-keyword">in</span> test.items():<br>        rank=Recommend(user,N) //rank:预测的列表-长度为N(n_precision)<br>        hit+=<span class="hljs-built_in">len</span>(rank&amp;items)   //items:实际的列表-T(U)-长度为<span class="hljs-built_in">len</span>(items)(n_recall)<br>        n_recall+=<span class="hljs-built_in">len</span>(items)<br>        n_precision+=N<br>    <span class="hljs-keyword">return</span> [hit/(<span class="hljs-number">1.0</span> * n_recall),hit/(<span class="hljs-number">1.0</span> * n_precision)<br></code></pre></td></tr></table></figure><p>​        为了全面评测TopN推荐的准确率和召回率,一般会选取不同的推荐长度N,计算出一组准确率&#x2F;召回率,然后画出准确率&#x2F;召回率曲线(precision&#x2F;recall curve).</p><ul><li>评分预测 VS TopN推荐</li></ul><p>研究人员一般都将精力集中在优化评分预测的RMSE上,但后来有人指出,电影推荐的目的是找到用户可能感兴趣的电影,而非预测看了电影后给出什么样的评分.例如,也许有一部分电影用户看了后会给出高分,但看的几率很小.因此,预测用户是否会看比看了之后给什么评分更加重要.因此,之后主要讨论TopN推荐.</p><h4 id="3-覆盖率"><a href="#3-覆盖率" class="headerlink" title="3. 覆盖率"></a>3. 覆盖率</h4><p>覆盖率(coverage)描述一个推荐系统对物品长尾的发掘能力.一般定义为推荐系统能够推荐出来的物品占总物品的比例,假设用户集合为$U$,RS给每个用户推荐一个长度为N的物品列表$R(u)$,则覆盖率可通过以下公式计算:<br>$$<br>Coverage&#x3D;\frac{|\cup_{u\in U}R(U)|}{|I|}<br>$$<br>因此,这是一个内容提供商会关注的指标.值为100%时,每个物品都至少被推荐给一个用户.好的推荐系统要有较高的用户满意度和较高的覆盖率.</p><p>需要注意的是,上面的定义是粗略的,因为100%覆盖率的RS可以有无数的物品流行度分布.因此可通过研究<strong>物品在推荐列表中出现次数的分布</strong>描述推荐系统挖掘长尾的能力,若该分布比较平,就说明覆盖率较高,陡峭则低.</p><p>在信息论和经济学中,还有两个指标可定义覆盖率:</p><ul><li>信息熵</li></ul><p>$$<br>H&#x3D;-\sum_{i&#x3D;1}^np(i)log\ p(i)<br>$$</p><p>$p(i)$指物品$i$的流行度占所有物品流行度的比.</p><ul><li>基尼系数(Gini Index)</li></ul><p>$$<br>G&#x3D;\frac{1}{n-1}\sum_{j&#x3D;1}^n(2j-n-1)p(i_j)<br>$$</p><p>$p(i_j)$是物品流行度$p()$按照<strong>从小到大</strong>排序的物品列表中第$j$个物品.</p><div align=center><img src="https://hicgoal-img.oss-cn-beijing.aliyuncs.com/img/image-20220315154509482.png" alt="基尼系数示例图" style="zoom:50%;" /></div><p>基尼系数的计算原理：</p><p>将物品按照热门程度从低到高排列，则右图中的黑色曲线表示最不热门的$x %$物品的总流行度占系统的比例$y%$。则这条曲线定在$y&#x3D;x$曲线之下。</p><p>基尼系数的形象定义就是$\frac{SA}{SA+SB}$,看以看出属于区间$[0,1]$,如果系统流行度很平均,$SA$会很小,基尼系数也很小,反之亦成立.</p><p>考虑这样一个问题,进入热门排行榜的物品都是热门商品,这些商品因为被放在榜中展示有了更多的曝光机会,因此会更加热门,这就是马太效应.</p><p>推荐系统的初衷是消除马太效应,使各种商品都能被展示给对其感兴趣的某一类人群.但一些推荐算法(如协同过滤)是具有马太效应的.</p><p>评测RS是否有马太效应的方法就是使用基尼系数.若$G_1$是从初始用户行为中计算得出的物品流行度的基尼系数,$G_2$是从推荐列表中计算出的物品流行度的基尼系数.如果$G_2&gt;G_1$,就说明推荐算法有马太效应.</p><h4 id="4-多样性"><a href="#4-多样性" class="headerlink" title="4. 多样性"></a>4. 多样性</h4><p>用户兴趣可能是广泛的,一个人可能喜欢《猫和老鼠》的同时也喜欢纪录片,因此推荐系统应该能够覆盖用户不同的兴趣领域.</p><p>此外，尽管用户的兴趣在较长的时间跨度是不一样的,但具体到用户访问的<strong>某一刻</strong>,其兴趣往往是单一的,如果推荐的某个兴趣点恰恰不是用户此时的兴趣点,推荐列表就不会让用户满意.因此推荐结果要具有多样性.</p><p>多样性定义了推荐列表中物品两两之间的不相似性.因此,多样性和相似性是对应的.假设$s(i,j)\in [0,1]$代表物品$i$和$j$之间的相似度,那么<strong>用户$u$的推荐列表$R(u)$多样性</strong>定义为:<br>$$<br>Diversity(R(u))&#x3D;1-\frac{\sum_{i,j\in R(u),i\neq j}s(i,j)}{\frac{1}{2}|R(u)|(|R(u)|-1)}<br>$$<br>推荐系统的整体多样性可定义为所有用户列表多样性的平均值:<br>$$<br>Diversity&#x3D;\frac{1}{|U|}\sum_{u\in U}Diversity(R(u))<br>$$<br>显然,不同的物品相似度$s(i,j)$可定义不同的多样性.e.g.,若用内容相似度描述$s(i,j)$,则可得到内容多样性函数;用协同过滤的的相似度函数描述$s(i,j)$,得到协同过滤的多样性函数.</p><p>推荐系统的多样性达到什么程度叫好?</p><p>e.g. 假设某用户喜欢A,B,且80%时间看A,20%时间看B.则最理想的推荐(以推荐10个为例)为推荐8个A,2个B</p><h4 id="5-新颖性"><a href="#5-新颖性" class="headerlink" title="5. 新颖性"></a>5. 新颖性</h4><p>新颖的推荐是指给用户推荐他们以前没有听说过的物品.<br>实现新颖性一个简单的办法是,把那些用户之前在网站中交互过的物品从推荐列表中过滤掉<br>新颖性可以利用推荐结果的平均流行度来度量.推荐结果中的平均热门程度越低推荐结果就可能有比较高的新颖性.这种评测比较粗略,因为不同用户不知道的东西不同,可能一个人偏爱冷门物品，此时对大多数人来说高新颖性的推荐列表反而对该用户低新颖性。因此准确的统计需要做用户调查<br>困难的是如何在不牺牲精度的情况下提高多样性和新颖性.</p><h4 id="6-惊喜度"><a href="#6-惊喜度" class="headerlink" title="6. 惊喜度"></a>6. 惊喜度</h4><p>基本意思:如果推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高<br>而推荐的新颖性仅仅取决于用户是否听说过这个推荐结果(推荐的电影主演和用户喜欢的主演一样,只是该用户之前没看过,这可以看作新颖性.但用户一旦了解了主演就不会特别奇怪,因此一般不视作惊喜度)。<br>目前并没有什么公认的惊喜度指标定义方式，这里只给出一种定性的度量方式:定义惊喜度需要首先定义推荐结果和用户历史上喜欢的物品的相似度，其次需要定义用户对推荐结果的满意度。前面也曾提到，用户满意度只能通过问卷调查或者在线实验获得，而推荐结果和用户历史上喜欢的物品相似度一般可以用内容相似度定义。<br>e.g. 如果获得了一个用户观看电影的历史，得到这些电影的演员和导演集合A，然后给用户推荐一个不属于集合A的导演和演员创作的电影，而用户表示非常满意，这样就实现了一个惊喜度很高的推荐。<br>因此<strong>提高推荐惊喜度需要提高推荐结果的用户满意度，同时降低推荐结果和用户历史兴趣的相似度。</strong></p><h4 id="7-信任度"><a href="#7-信任度" class="headerlink" title="7. 信任度"></a>7. 信任度</h4><p>考虑两个推荐系统,它们的推荐结果相同，但用户却可能产生不同的反应，这就是因为用户对他们有不同的信任度。如果用户信任推荐系统，那就会增加用户和推荐系统的交互。特别是在电于商务推荐系统中，让用户对推荐结果产生信任非常重要.<br>该指标的度量只能通过问卷调查的方式.<br>提高推荐系统的信任度主要有两种方法。</p><ul><li>增加推荐系统的透明度（transpareney)，主要办法是提供推荐解释。只有让用户了解推荐系统的运行机制，让用户认同推荐系统的运行机制，才会提高用户对推荐系统的信任度。- 考虑用户的社交网络信息，利用用户的好友信息给用户做推荐，并且用好友进行推荐解释。这是因为用户对他们的好友一般都比较信任.</li></ul><h4 id="8-实时性"><a href="#8-实时性" class="headerlink" title="8. 实时性"></a>8. 实时性</h4><p>某些物品(新闻,微博)有很强的时效性,因此需要在其具有时效性时就将它们推荐给用户.RS的实时性包括两个方面:</p><ul><li>需要实时地更新推荐列表来满足用户新的行为变化。比如，当一个用户购买了iPhone，如果推荐系统能够立即给他推荐相关配件，那么肯定比第二天再给用户推荐相关配件更有价值。很多推荐系统都会在离线状态每天计算一次用户推荐列表，然后于在线期间将推荐列表展示给用户。这种设计显然是无法满足实时性的。与用户行为相应的实时性，评测方法:推荐列表的变化速率。如果推荐列表在用户有行为后变化不大，或者没有变化，说明推荐系统的实时性不高。</li><li>需要能够将新加入系统的物品推荐给用户。这主要考验了推荐系统处理物品冷启动的能力。评测方法:可以利用用户推荐列表中有多大比例的物品是当天新加的来评测。</li></ul><h4 id="9-健壮性"><a href="#9-健壮性" class="headerlink" title="9. 健壮性"></a>9. 健壮性</h4><p>健壮性（即robust鲁棒性）衡量推荐系统抗击作弊的能力。e.g.行为注入攻击:亚马逊有一种推荐叫做“购买商品A的用户也经常购买的其他商品”。它的主要计算方法是统计购买商品A的用户购买其他商品的次数。可以攻击这个算法，让<strong>自己的商品</strong>在这个推荐列表中获得比较高的排名，比如可以注册很多账号，用这些账号同时购买A和自己的商品。还有一种攻击主要针对评分系统雇用一批人给自己的商品非常高的评分，而评分行为是推荐系统依赖的重要用户行为。<br>算法健壮性的评测主要利用模拟攻击。首先，给定一个数据集和一个算法，可以用这个算法<br>给这个数据集中的用户生成推荐列表。然后，用常用的攻击方法向数据集中注入噪声数据，然后利用算法在注入噪声后的数据集上再次给用户生成推荐列表。最后，通过比较攻击前后推荐列表的相似度评测算法的健壮性。<br>在实际系统中，提高系统的健壮性，除了选择健壮性高的算法，还有以下方法。</p><ul><li>设计推荐系统时尽量使用代价比较高的用户行为。比如，如果有用户购买行为和用户浏<br>览行为，那么主要应该使用用户购买行为，因为购买需要付费，所以攻击购买行为的代<br>价远远大于攻击浏览行为。</li><li>在使用数据前，进行攻击检测，从而对数据进行清理。</li></ul><h4 id="10-商业目标"><a href="#10-商业目标" class="headerlink" title="10.商业目标"></a>10.商业目标</h4><p>不同公司会根据自己的盈利模式设计不同的商业目标,例如电商网站的目标可能是销售额,基于展示&#x2F;点击广告盈利的网站其商业目标可能是广告&#x2F;点击展示总数.<br>因此,设计推荐系统需要考虑最终的商业目标,网站使用推荐系统的目的除了满足用户发现内容的需求,也需要利用推荐系统加快实现商业上的目标.</p><h4 id="11-总结"><a href="#11-总结" class="headerlink" title="11.总结"></a>11.总结</h4><p>上面提到的指标有些可以离线计算,有的只能在线获得.如何<strong>优化离线指标来提高在线指标</strong>是推荐系统研究的重要问题.<br>$\circ$指得到的统计不准确</p><p>发</p><table><thead><tr><th align="center"></th><th align="center">离线实验</th><th align="center">文件调查</th><th align="center">在线实验</th></tr></thead><tbody><tr><td align="center">用户满意度</td><td align="center">$\times$</td><td align="center">$\checkmark$</td><td align="center">$\circ$</td></tr><tr><td align="center">预测准确度</td><td align="center">$\checkmark$</td><td align="center">$\checkmark$</td><td align="center">$\times$</td></tr><tr><td align="center">覆盖率</td><td align="center">$\checkmark$</td><td align="center">$\checkmark$</td><td align="center">$\checkmark$</td></tr><tr><td align="center">多样性</td><td align="center">$\circ$</td><td align="center">$\checkmark$</td><td align="center">$\circ$</td></tr><tr><td align="center">新颖性</td><td align="center">$\circ$</td><td align="center">$\checkmark$</td><td align="center">$\circ$</td></tr><tr><td align="center">惊喜度</td><td align="center">$\times$</td><td align="center">$\checkmark$</td><td align="center">$\times$</td></tr></tbody></table><p>对于可以离线优化的指标，书中认为应该是在给定覆盖率、多样性、新颖性等限制条件下，尽量优化预测准确度。因此离线实验的优化目标可以表示为：<br>$$<br>最大化预测准确度\<br>使得\quad 覆盖率&gt;A\<br>\qquad \quad多样性&gt;B\<br>\qquad \quad新颖性&gt;C<br>$$</p><h2 id="1-3-3-评测维度"><a href="#1-3-3-评测维度" class="headerlink" title="1.3.3 评测维度"></a>1.3.3 评测维度</h2><p>评测系统除了上述指标还要考虑评测维度.增加评测维度能让我们知道一个算法在什么情况下性能最好,为融合不同推荐算法取得最好的整体性能带来参考.<br>一般评测维度分为以下三种:</p><ul><li><strong>用户维度</strong>主要包括用户的人口统计学信息、活跃度以及是不是新用户等。</li><li><strong>物品维度</strong>包括物品的属性信息、流行度、平均分以及是不是新加入的物品等。</li><li><strong>时间维度</strong>包括季节，是工作日还是周末，是白天还是晚上等。<br>如果能够在推荐系统评测报告中包含不同维度下的系统评测指标，就能帮我们全面地了解推荐系统性能，找到一个看上去比较弱的算法的优势，发现一个看上去比较强的算法的缺点。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>读书笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/02/25/hello-world/"/>
    <url>/2022/02/25/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
